{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4169d286",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"cs109a_hw4.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66f40a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109A Introduction to Data Science\n",
    "\n",
    "## Homework 4: Missing Data & PCA\n",
    "\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2022**<br/>\n",
    "**Instructors**: Pavlos Protopapas, Natesh Pillai\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a4748d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 {\n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left;\n",
       "    padding-left: 10px;\n",
       "    background-color: #63ACBE;\n",
       "    color: black;\n",
       "}\n",
       "h2 {\n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left;\n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE;\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #f8b4ab;\n",
       "\tborder-color: #E9967A;\n",
       "\tborder-left: 5px solid #601A4A;\n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "div.exercise-r {\n",
       "\tbackground-color: #ffd0d0;\n",
       "\tborder-color: #E9967A;\n",
       "\tborder-left: 5px solid #601A4A;\n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "\n",
       "span.sub-q {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #63ACBE;\n",
       "\tborder-color: #E9967A;\n",
       "\tborder-left: 5px solid #601A4A;\n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc {\n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A;\n",
       "\tborder-left: 5px solid #601A4A;\n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 {\n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left;\n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE;\n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left;\n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD;\n",
       "    color: black;\n",
       "}\n",
       "span.emph {\n",
       "\tcolor: #601A4A;\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\n",
    "    \"https://raw.githubusercontent.com/Harvard-IACS/2021-CS109A/master/\"\n",
    "    \"themes/static/css/cs109.css\"\n",
    ").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358f0643",
   "metadata": {},
   "source": [
    "#### Instructions\n",
    "- To submit your assignment follow the instructions given in Canvas.\n",
    "- Plots should be legible and interpretable without having to refer to the code that generated them, including labels for the $x$- and $y$-axes as well as a descriptive title and/or legend when appropriate.\n",
    "- When asked to interpret a visualization, do not simply describe it (e.g., \"the curve has a steep slope up\"), but instead explain what you think the plot *means*.\n",
    "- The use of 'hard-coded' values to try and pass tests rather than solving problems programmatically will not receive credit.\n",
    "- The use of *extremely* inefficient or error-prone code (e.g., copy-pasting nearly identical commands rather than looping) may result in only partial credit.\n",
    "- We have tried to include all the libraries you may need to do the assignment in the imports cell provided below. Please get course staff approval before importing any additional 3rd party libraries.\n",
    "- Enable scrolling output on cells with very long output.\n",
    "- Feel free to add additional code or markdown cells as needed.\n",
    "- Ensure your code runs top to bottom without error and passes all tests by restarting the kernel and running all cells. This is how the notebook will be evaluated (note that this can take a few minutes). \n",
    "- **You should do a \"Restart Kernel and Run All Cells\" before submitting to ensure (1) your notebook actually runs and (2) all output is visible**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83e5010",
   "metadata": {
    "cell_id": "3c67b69c-c35a-45ee-88ff-99c701edb0a0",
    "colab_type": "text",
    "id": "BlViDCbxVtbG"
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83a1a9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL\n",
    "\n",
    "# Import libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "# pandas tricks for better display\n",
    "pd.options.display.max_columns = 50  \n",
    "pd.options.display.max_rows = 500     \n",
    "pd.options.display.max_colwidth = 100\n",
    "pd.options.display.precision = 3\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dcd104",
   "metadata": {},
   "source": [
    "<a id=\"contents\"></a>\n",
    "\n",
    "## Notebook contents\n",
    "\n",
    "- [**PART 1 [55 pts]: Predicting the selling price of used cars (missing data)**](#part1)\n",
    "  - [Overview and Data Description](#part1intro)\n",
    "  - [Question 1: Visualizing Missing Data [10 pts]](#part1q1)\n",
    "      - [Solutions](#part1q1solution)\n",
    "  - [Question 2: Imputation Methods [45 pts]](#part1q2)\n",
    "      - [Solutions](#part1q2solution)\n",
    "\n",
    "\n",
    "- [**PART 2 [45 pts]: Principal Componant Analysis**](#part2)\n",
    "  - [Question 3: PCA for Regression [35 pts]](#part2q3)\n",
    "      - [Solutions](#part2q3solution)\n",
    "  - [Question 4: Visualizing Transformed Data [10 pts]](#part2q4)\n",
    "      - [Solutions](#part2q4solution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d69f71",
   "metadata": {},
   "source": [
    "<a id=\"part1\"></a>\n",
    "    \n",
    "# PART 1 [55 pts]: Predicting the selling price of used cars (missing data)\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630e36c6",
   "metadata": {},
   "source": [
    "<a id=\"part1intro\"></a>\n",
    "\n",
    "## Overview and Data Description \n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "In this part, we analyze the data about used cars from a [Kaggle project](https://www.kaggle.com/nehalbirla/vehicle-dataset-from-cardekho). The dataset is pre-processed and modified so that it contains missing values. The goal is to handle missing data and predict selling prices from the other features available in this dataset.\n",
    "\n",
    "### Dataset \n",
    "\n",
    "The training dataset is available as `data/vehicle_dataset_train.csv`. It contains the following columns:\n",
    "\n",
    "- `year` - year of the car when it was bought, \n",
    "- `mileage` - mileage of the car,\n",
    "- `max_power` - maximum power of the engine (in bhps),\n",
    "- `selling_price` - price at which the car is being sold (in lakh rupees)\n",
    "\n",
    "The testing dataset is available as `data/vehicle_dataset_test.csv`. It contains all columns mentioned above.\n",
    "\n",
    "\n",
    "### Objective\n",
    "\n",
    "We will handle missing data and predict `selling_price` from the other features available in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525c0796",
   "metadata": {},
   "source": [
    "<a id=\"part1q1\"></a>\n",
    "\n",
    "## <div class='exercise'><b>Question 1: Visualizing Missing Data [10 pts]</b></div>\n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "**PLEASE NOTE:** In this course, you will be expected to ALWAYS label your axes, title your graphs, and produce visuals which clearly communicate the data (as described in the [Instructions](#instructions) at the start of this notebook). Visuals should often be accompanied by text identifying the key point of the visual and defending any choices you make as a data scientist regarding the visual to best communicate your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acc52dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>mileage</th>\n",
       "      <th>max_power</th>\n",
       "      <th>selling_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6601</th>\n",
       "      <td>2015</td>\n",
       "      <td>17.40</td>\n",
       "      <td>117.30</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>2017</td>\n",
       "      <td>13.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>262.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5812</th>\n",
       "      <td>2018</td>\n",
       "      <td>24.00</td>\n",
       "      <td>73.97</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>2009</td>\n",
       "      <td>19.70</td>\n",
       "      <td>46.30</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7453</th>\n",
       "      <td>2014</td>\n",
       "      <td>16.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  mileage  max_power  selling_price\n",
       "6601  2015    17.40     117.30           70.0\n",
       "504   2017    13.60        NaN          262.5\n",
       "5812  2018    24.00      73.97           71.0\n",
       "1443  2009    19.70      46.30           15.0\n",
       "7453  2014    16.02        NaN           42.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the datasets\n",
    "df_train = pd.read_csv(\"data/vehicle_dataset_train.csv\", index_col=0)\n",
    "df_test = pd.read_csv(\"data/vehicle_dataset_test.csv\", index_col=0)\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ca5c656-13fe-447a-8b4e-647d49d1138e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>mileage</th>\n",
       "      <th>max_power</th>\n",
       "      <th>selling_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>2018</td>\n",
       "      <td>19.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6026</th>\n",
       "      <td>2014</td>\n",
       "      <td>24.00</td>\n",
       "      <td>70.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>2011</td>\n",
       "      <td>18.00</td>\n",
       "      <td>62.0</td>\n",
       "      <td>16.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3340</th>\n",
       "      <td>2014</td>\n",
       "      <td>20.92</td>\n",
       "      <td>67.1</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5325</th>\n",
       "      <td>2014</td>\n",
       "      <td>25.20</td>\n",
       "      <td>74.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  mileage  max_power  selling_price\n",
       "1979  2018    19.62        NaN          335.0\n",
       "6026  2014    24.00       70.0           46.0\n",
       "1781  2011    18.00       62.0           16.9\n",
       "3340  2014    20.92       67.1           25.5\n",
       "5325  2014    25.20       74.0           57.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57e8a0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate predictors from responsess\n",
    "X_train, y_train = df_train.drop(columns=['selling_price']), df_train['selling_price']\n",
    "X_test, y_test = df_test.drop(columns=['selling_price']), df_test['selling_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e586f5f2",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**Q1.1** Let's explore the extent of the missingness in the train data:\n",
    "\n",
    "- store the number of rows with missing values in `n_rows_with_missingness`\n",
    "- store the number of columns with missing values in `n_columns_with_missingness`\n",
    "- Create a Pandas Series where the indices are the column names of `X_train` and the values are the number of missing data entries in the corresponding column in `X_train`. Store this series in `col_missingness`\n",
    "</div> \n",
    "\n",
    "_Points:_ 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a7a4e16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_rows_with_missingness = X_train.isna().any(axis=1).sum()\n",
    "n_cols_with_missingness = X_train.isna().any(axis=0).sum()\n",
    "col_missingness = X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52ee5487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# rows with missingness: 44\n",
      "# columns with missingness: 1\n",
      "\n",
      "columns with missingness:\n",
      "year          0\n",
      "mileage       0\n",
      "max_power    44\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# display your results with this code\n",
    "print('# rows with missingness:', n_rows_with_missingness)\n",
    "print('# columns with missingness:', n_cols_with_missingness)\n",
    "print(f'\\ncolumns with missingness:\\n{col_missingness}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "519e1598",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1.1</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q1.1 results: All test cases passed!"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e679cecc",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**1.2** Generate a boxplot of `year` for all samples that have missing values. In the same plot, generate another boxplot of `year` for all samples that do not have missing values. Do you see any pattern?  If so, what might be the implications of that pattern? \n",
    "\n",
    "</div> \n",
    "\n",
    "_Points:_ 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d25cbc6",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76aaf0d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# your code here\n",
    "X_train_new = X_train.copy()\n",
    "X_train_new['has_missing_value'] = X_train_new['max_power'].isna()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.boxplot(data=X_train_new, x = 'has_missing_value', y='year', palette = 'pastel')\n",
    "plt.title('Boxplot of `year` variable')\n",
    "plt.ylabel('year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c0ef59",
   "metadata": {
    "tags": []
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<a id=\"part1q2\"></a>\n",
    "\n",
    "## <div class='exercise'><b> Question 2:   Imputation Methods [45 pts]</b></div>\n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "We will try different ways of dealing with missing data. Take care not to overwrite the original `X_train` and `X_test` as we'll want to use them each time we try a new imputation method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acc245c",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "    \n",
    "\n",
    "**2.1** First, we consider mean imputation:\n",
    "  - Use SimpleImputer to impute the mean of observed `max_power` values in the training dataset for both **X_train** and **X_test**. \n",
    "  - Fit a linear regression model and store its $R^2$ score on the test data in `linreg_meanimp_r2`\n",
    "  - Fit a k-NN regression model ($k$=2) store its $R^2$ score on the test data in `knn_meanimp_r2` \n",
    "    \n",
    "**NOTE:** For the sake of consistency, we will used standardized data throughout question 2 (consider why this is necessary for at least some of our models and imputation methods). Note that we are fitting our scaler on *all* the data (train + test).\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50d93e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(np.concatenate([X_train.values, X_test.values], axis=0))\n",
    "X_train_scaled = scaler.transform(X_train.values)\n",
    "X_test_scaled = scaler.transform(X_test.values)\n",
    "# Add back column names lost during scaling\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f37cfe51-cd64-4d26-a5da-0b3ea5ff2964",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_copy = X_train_scaled.copy()\n",
    "X_test_scaled_copy = X_test_scaled.copy()\n",
    "\n",
    "imputer = SimpleImputer()\n",
    "imputer.fit(X_train_scaled_copy)\n",
    "\n",
    "X_train_scaled_copy = imputer.transform(X_train_scaled_copy)\n",
    "X_test_scaled_copy = imputer.transform(X_test_scaled_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6babf20-1be9-4944-b5e7-1451a5200cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression().fit(X_train_scaled_copy, y_train)\n",
    "knn = KNeighborsRegressor(n_neighbors=int(2)).fit(X_train_scaled_copy, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c7987a4-fb3d-4f16-9cab-e988d0adcb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_meanimp_r2 = linreg.score(X_test_scaled_copy, y_test)\n",
    "knn_meanimp_r2 = knn.score(X_test_scaled_copy, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2624d77-fac4-4dbf-824a-ed8b311c8f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.18938054143276772, 0.40091818913113364)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg_meanimp_r2,knn_meanimp_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fe70432",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2.1</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2.1 results: All test cases passed!"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba17f06a",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**2.2** Now, we will impute the data using k-NN regression model and see how it works:\n",
    "  - Use KNNImputer ($k$=2) to impute both **X_train** and **X_test**.\n",
    "  - Fit a linear regression model and store its $R^2$ score on the test data in `linreg_knnimp_r2`\n",
    "  - Fit a k-NN regression model ($k$=2) store its $R^2$ score on the test data in `knn_knnimp_r2` \n",
    "</div>\n",
    "\n",
    "_Points:_ 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3dd61e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "X_train2 = X_train_scaled.copy()\n",
    "X_test2 = X_test_scaled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "013275ad-12c1-4cac-a212-52a40f7b8fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer2 = KNNImputer(n_neighbors=2)\n",
    "imputer2.fit(X_train2)\n",
    "\n",
    "X_train2_t = imputer2.transform(X_train2)\n",
    "X_test2_t = imputer2.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f034e48f-c9ae-47ef-bba7-4c849636c6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg2 = LinearRegression().fit(X_train2_t, y_train)\n",
    "knn2 = KNeighborsRegressor(n_neighbors=int(2)).fit(X_train2_t, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28aea48e-b8b2-46aa-885a-b012470c5d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_knnimp_r2 = linreg2.score(X_test2_t, y_test)\n",
    "knn_knnimp_r2 = knn2.score(X_test2_t, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e26e2d9f-ef9e-4c85-899f-7cf669ca2565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.20459016028096277, 0.6195017436510428)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg_knnimp_r2, knn_knnimp_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f2d5db2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2.2</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2.2 results: All test cases passed!"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcb183e",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "    \n",
    "**2.3** Now, let's examine the indicator method:\n",
    "  - For both the training and testing data, create an additional predictor called `has_missing_value` that indicates whether each row has any missing value.\n",
    "  - Impute the mean of observed `max_power` values in the training dataset for both **X_train** and **X_test**.\n",
    "  - Fit a linear regression model and store its $R^2$ score on the test data in `linreg_indic_r2`\n",
    "  - Fit a k-NN regression model ($k$=2) store its $R^2$ score on the test data in `knn_indic_r2` \n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "78825c63-fe5f-43c4-afc1-86f7383db254",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled['has_missing_value']=pd.isnull(X_test_scaled[\"max_power\"])\n",
    "X_train_scaled['has_missing_value']=pd.isnull(X_train_scaled[\"max_power\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "81c0cad0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train3 = X_train_scaled.copy()\n",
    "X_test3 = X_test_scaled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9b2c0a4c-403d-4bb8-9355-2d03c044381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer3 = SimpleImputer()\n",
    "imputer3.fit(X_train3)\n",
    "\n",
    "X_train3_t = imputer3.transform(X_train3)\n",
    "X_test3_t = imputer3.transform(X_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "36be4be3-81be-4bab-842a-c21a8b4ccf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg3 = LinearRegression().fit(X_train3_t, y_train)\n",
    "knn3 = KNeighborsRegressor(n_neighbors=int(2)).fit(X_train3_t, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "421e3952-a848-46d5-9608-9e38cc017175",
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_indic_r2 = linreg3.score(X_test3_t, y_test)\n",
    "knn_indic_r2 = knn3.score(X_test3_t, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "efc7b762-9ddf-4fb6-ad3d-ba15922e1b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3947819661877334, 0.6524888317006119)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg_indic_r2, knn_indic_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7aab3dd6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2.3</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2.3 results: All test cases passed!"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441ce4f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**2.4** Compare the $R^2$ values in **2.1** and **2.3**. Does adding an indicator variable help? Do these indicator method results provide any support **for** or **against** a claim that the data is missing completely at random? Why or why not?\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "06e8258b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linreg test $R^2$</th>\n",
       "      <th>knn test $R^2$</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missingness approach</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean imputation</th>\n",
       "      <td>0.189</td>\n",
       "      <td>0.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn imputation</th>\n",
       "      <td>0.205</td>\n",
       "      <td>0.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missingness indicator + mean imputation</th>\n",
       "      <td>0.395</td>\n",
       "      <td>0.652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         linreg test $R^2$  knn test $R^2$\n",
       "missingness approach                                                      \n",
       "mean imputation                                      0.189           0.620\n",
       "knn imputation                                       0.205           0.620\n",
       "missingness indicator + mean imputation              0.395           0.652"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display your results\n",
    "pd.DataFrame([\n",
    "    {'missingness approach': 'mean imputation',\n",
    "     'linreg test $R^2$': linreg_meanimp_r2,\n",
    "     'knn test $R^2$': knn_knnimp_r2},\n",
    "    {'missingness approach': 'knn imputation',\n",
    "     'linreg test $R^2$': linreg_knnimp_r2,\n",
    "     'knn test $R^2$': knn_knnimp_r2},\n",
    "    {'missingness approach': 'missingness indicator + mean imputation',\n",
    "     'linreg test $R^2$': linreg_indic_r2,\n",
    "     'knn test $R^2$': knn_indic_r2}, \n",
    "]).set_index('missingness approach')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68d5ba7",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db12b8e",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<a id=\"part2\"></a>\n",
    "    \n",
    "# PART 2 [45 pts]: Principal Component Analysis\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9e20df",
   "metadata": {},
   "source": [
    "<a id=\"part2q3\"></a>\n",
    "\n",
    "## <div class='exercise'><b> Question 3: PCA for Regression [35 pts]</b></div>\n",
    "\n",
    "[Return to contents](#contents)\n",
    " \n",
    "\n",
    "In this question, we will be using a dataset called \"Communities and Crime\" adapted from [UC Irvine Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets/Communities+and+Crime). The modified dataset contains 122 predictor variables and 1 response variable. All numeric data was normalized into the decimal range 0.00-1.00. Some of the predictor variables are:\n",
    "\n",
    "- `householdsize`: mean people per household\n",
    "- `medIncome`: median household income\n",
    "- `PctHousOccup`: percent of housing occupied\n",
    "- `RentMedian`: rental housing - median rent\n",
    "- `PolicReqPerOffic`: total requests for police per police officer\n",
    "\n",
    "And the response variable is \n",
    "\n",
    "- `ViolentCrimesPerPop`: total number of violent crimes per 100K popuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ad1584e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>agePct65up</th>\n",
       "      <th>numbUrban</th>\n",
       "      <th>pctUrban</th>\n",
       "      <th>medIncome</th>\n",
       "      <th>pctWWage</th>\n",
       "      <th>pctWFarmSelf</th>\n",
       "      <th>pctWInvInc</th>\n",
       "      <th>pctWSocSec</th>\n",
       "      <th>pctWPubAsst</th>\n",
       "      <th>pctWRetire</th>\n",
       "      <th>medFamInc</th>\n",
       "      <th>perCapInc</th>\n",
       "      <th>whitePerCap</th>\n",
       "      <th>blackPerCap</th>\n",
       "      <th>indianPerCap</th>\n",
       "      <th>AsianPerCap</th>\n",
       "      <th>...</th>\n",
       "      <th>LemasSwFTFieldOps</th>\n",
       "      <th>LemasSwFTFieldPerPop</th>\n",
       "      <th>LemasTotalReq</th>\n",
       "      <th>LemasTotReqPerPop</th>\n",
       "      <th>PolicReqPerOffic</th>\n",
       "      <th>PolicPerPop</th>\n",
       "      <th>RacialMatchCommPol</th>\n",
       "      <th>PctPolicWhite</th>\n",
       "      <th>PctPolicBlack</th>\n",
       "      <th>PctPolicHisp</th>\n",
       "      <th>PctPolicAsian</th>\n",
       "      <th>PctPolicMinor</th>\n",
       "      <th>OfficAssgnDrugUnits</th>\n",
       "      <th>NumKindsDrugsSeiz</th>\n",
       "      <th>PolicAveOTWorked</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>PolicCars</th>\n",
       "      <th>PolicOperBudg</th>\n",
       "      <th>LemasPctPolicOnPatr</th>\n",
       "      <th>LemasGangUnitDeploy</th>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "      <th>PolicBudgPerPop</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   population  householdsize  racepctblack  racePctWhite  racePctAsian  \\\n",
       "0        0.19           0.33          0.02          0.90          0.12   \n",
       "1        0.15           0.31          0.40          0.63          0.14   \n",
       "2        0.25           0.54          0.05          0.71          0.48   \n",
       "3        1.00           0.42          0.47          0.59          0.12   \n",
       "4        0.11           0.43          0.04          0.89          0.09   \n",
       "\n",
       "   racePctHisp  agePct12t21  agePct12t29  agePct16t24  agePct65up  numbUrban  \\\n",
       "0         0.17         0.34         0.47         0.29        0.32       0.20   \n",
       "1         0.06         0.58         0.72         0.65        0.47       0.16   \n",
       "2         0.30         0.42         0.48         0.28        0.32       0.26   \n",
       "3         0.05         0.41         0.53         0.34        0.33       1.00   \n",
       "4         0.06         0.45         0.48         0.31        0.46       0.13   \n",
       "\n",
       "   pctUrban  medIncome  pctWWage  pctWFarmSelf  pctWInvInc  pctWSocSec  \\\n",
       "0      1.00       0.37      0.72          0.34        0.60        0.29   \n",
       "1      1.00       0.22      0.52          0.10        0.51        0.48   \n",
       "2      1.00       0.33      0.55          0.37        0.37        0.39   \n",
       "3      0.99       0.28      0.62          0.16        0.36        0.40   \n",
       "4      1.00       0.22      0.52          0.44        0.49        0.56   \n",
       "\n",
       "   pctWPubAsst  pctWRetire  medFamInc  perCapInc  whitePerCap  blackPerCap  \\\n",
       "0         0.15        0.43       0.39       0.40         0.39         0.32   \n",
       "1         0.39        0.51       0.30       0.29         0.34         0.23   \n",
       "2         0.64        0.44       0.32       0.29         0.32         0.23   \n",
       "3         0.30        0.45       0.29       0.30         0.35         0.21   \n",
       "4         0.41        0.39       0.25       0.25         0.25         0.16   \n",
       "\n",
       "   indianPerCap  AsianPerCap  ...  LemasSwFTFieldOps  LemasSwFTFieldPerPop  \\\n",
       "0          0.27         0.27  ...               0.96                  0.17   \n",
       "1          0.13         0.20  ...               0.93                  0.38   \n",
       "2          0.17         0.17  ...               0.96                  0.12   \n",
       "3          0.20         0.33  ...               0.75                  0.19   \n",
       "4          0.07         0.20  ...               0.98                  0.14   \n",
       "\n",
       "   LemasTotalReq  LemasTotReqPerPop  PolicReqPerOffic  PolicPerPop  \\\n",
       "0           0.06               0.18              0.44         0.13   \n",
       "1           0.05               0.21              0.23         0.30   \n",
       "2           0.05               0.11              0.35         0.08   \n",
       "3           0.35               0.19              0.38         0.16   \n",
       "4           0.03               0.14              0.37         0.11   \n",
       "\n",
       "   RacialMatchCommPol  PctPolicWhite  PctPolicBlack  PctPolicHisp  \\\n",
       "0                0.94           0.93           0.03          0.07   \n",
       "1                0.61           0.89           0.15          0.01   \n",
       "2                0.80           0.82           0.04          0.19   \n",
       "3                0.82           0.70           0.45          0.03   \n",
       "4                0.84           0.96           0.00          0.00   \n",
       "\n",
       "   PctPolicAsian  PctPolicMinor  OfficAssgnDrugUnits  NumKindsDrugsSeiz  \\\n",
       "0           0.10           0.07                 0.02               0.57   \n",
       "1           0.06           0.12                 0.10               0.64   \n",
       "2           0.19           0.18                 0.05               0.57   \n",
       "3           0.05           0.33                 0.13               0.57   \n",
       "4           0.00           0.00                 0.02               0.86   \n",
       "\n",
       "   PolicAveOTWorked  LandArea  PopDens  PctUsePubTrans  PolicCars  \\\n",
       "0              0.29      0.12     0.26            0.20       0.06   \n",
       "1              0.22      0.06     0.39            0.84       0.06   \n",
       "2              0.36      0.09     0.46            0.05       0.09   \n",
       "3              1.00      1.00     0.07            0.15       1.00   \n",
       "4              0.29      0.16     0.12            0.07       0.04   \n",
       "\n",
       "   PolicOperBudg  LemasPctPolicOnPatr  LemasGangUnitDeploy  \\\n",
       "0           0.04                 0.90                  0.5   \n",
       "1           0.06                 0.91                  0.5   \n",
       "2           0.05                 0.88                  0.5   \n",
       "3           0.35                 0.73                  0.0   \n",
       "4           0.01                 0.81                  1.0   \n",
       "\n",
       "   LemasPctOfficDrugUn  PolicBudgPerPop  ViolentCrimesPerPop  \n",
       "0                 0.32             0.14                 0.20  \n",
       "1                 0.88             0.26                 0.49  \n",
       "2                 0.76             0.13                 0.34  \n",
       "3                 0.31             0.21                 0.69  \n",
       "4                 0.56             0.09                 0.63  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the datasets\n",
    "df = pd.read_csv(\"data/communities_and_crime.csv\", index_col = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1cf4cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate predictors and response\n",
    "X, y = df.drop(columns=['ViolentCrimesPerPop']), df['ViolentCrimesPerPop']\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e1eb17",
   "metadata": {},
   "source": [
    "<a id=\"part2q3solution\"></a>\n",
    "## Question 3: Solutions \n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b1d0d2",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**3.1** Compute the correlation matrix for the predictor variables in the training data (DO NOT print the entire matrix). Which pairs of distinct predictor variables have correlation greater than 0.99 or less than -0.99? \n",
    "    \n",
    "Store these pairs in a dictionary called `high_corr` where the keys are tuples corresponding to the names of the pair of predictors and the values are the correlation between each pair.\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c1227455-41b1-4d80-b21a-b27ed0457243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.02688726,  0.21637562, ...,  0.14674373,\n",
       "        -0.17636656, -0.00942782],\n",
       "       [-0.02688726,  1.        ,  0.04598497, ...,  0.0136492 ,\n",
       "         0.0551015 , -0.14185133],\n",
       "       [ 0.21637562,  0.04598497,  1.        , ...,  0.0392468 ,\n",
       "         0.08320129,  0.01694902],\n",
       "       ...,\n",
       "       [ 0.14674373,  0.0136492 ,  0.0392468 , ...,  1.        ,\n",
       "        -0.02712466, -0.06303336],\n",
       "       [-0.17636656,  0.0551015 ,  0.08320129, ..., -0.02712466,\n",
       "         1.        ,  0.03321257],\n",
       "       [-0.00942782, -0.14185133,  0.01694902, ..., -0.06303336,\n",
       "         0.03321257,  1.        ]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std = ((X_train-X_train.mean(axis=0))/X_train.std())\n",
    "N = X_std.shape[0]\n",
    "X_cov = np.dot(X_std.T, X_std) / (N-1)\n",
    "X_cov.shape\n",
    "X_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ff4fe6e0-49e3-4c6e-a96f-d23360100bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10715827, 0.09717756, 0.09571102, ..., 0.11318898, 0.1272    ,\n",
       "        0.04282047],\n",
       "       [0.09717756, 0.20379724, 0.1498937 , ..., 0.18509843, 0.25824173,\n",
       "        0.07669764],\n",
       "       [0.09571102, 0.1498937 , 0.22072913, ..., 0.15476378, 0.21514409,\n",
       "        0.06583346],\n",
       "       ...,\n",
       "       [0.11318898, 0.18509843, 0.15476378, ..., 0.3484252 , 0.25665354,\n",
       "        0.07712598],\n",
       "       [0.1272    , 0.25824173, 0.21514409, ..., 0.25665354, 0.43223465,\n",
       "        0.11403937],\n",
       "       [0.04282047, 0.07669764, 0.06583346, ..., 0.07712598, 0.11403937,\n",
       "        0.05950709]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = X_train.shape[0]\n",
    "X_cov = np.dot(X_train.T, X_train) / (N-1)\n",
    "X_cov.shape\n",
    "X_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c1cd53ce-2a68-41d9-bc34-6e7b1a509133",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "321117f4-2335-4fc6-963b-c10682b62ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_corr = {}\n",
    "\n",
    "for i in range(122):\n",
    "    for j in range(122):\n",
    "        if np.abs(X_cov[i,j]) > 0.99:\n",
    "            high_corr[col[i],col[j]]=X_cov[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12363b4a-f93f-41c1-9c51-28a1a1df746f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a1b790-bef4-4746-87de-a729c9e36522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2cea0d93",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following pairs of predictor variables have correlation greater than 0.99 or less than -0.99:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "high_corr = test\n",
    "print(\"The following pairs of predictor variables have correlation greater than 0.99 or less than -0.99:\")\n",
    "display(high_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "99f87837-0998-4e0b-9efd-a64768e4fe8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [96]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m high_corr \u001b[38;5;241m=\u001b[39m {k: np\u001b[38;5;241m.\u001b[39mfloat64(v) \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m \u001b[43mhigh_corr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m()}\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "high_corr = {k: np.float64(v) for k,v in high_corr.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fd88da71",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>q3.1</pre> results:</strong></p><p><strong><pre style='display: inline;'>q3.1 - 1</pre> result:</strong></p><pre>    Trying:\n",
       "        assert type(high_corr) == dict and len(high_corr) == 9,\\\n",
       "        \"high_corr should be a dict with 9 entries\"\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 1, in q3.1 0\n",
       "    Failed example:\n",
       "        assert type(high_corr) == dict and len(high_corr) == 9,\\\n",
       "        \"high_corr should be a dict with 9 entries\"\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/Users/karenkuo/opt/anaconda3/lib/python3.9/doctest.py\", line 1334, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q3.1 0[0]>\", line 1, in <module>\n",
       "            assert type(high_corr) == dict and len(high_corr) == 9,\\\n",
       "        AssertionError: high_corr should be a dict with 9 entries\n",
       "</pre><p><strong><pre style='display: inline;'>q3.1 - 2</pre> result:</strong></p><pre>    Trying:\n",
       "        assert all([type(k) == tuple and len(k) == 2 for k in high_corr.keys()]),\\\n",
       "        \"keys of high_corr should be tuples of length 2\"\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 1, in q3.1 1\n",
       "    Failed example:\n",
       "        assert all([type(k) == tuple and len(k) == 2 for k in high_corr.keys()]),\\\n",
       "        \"keys of high_corr should be tuples of length 2\"\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/Users/karenkuo/opt/anaconda3/lib/python3.9/doctest.py\", line 1334, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q3.1 1[0]>\", line 1, in <module>\n",
       "            assert all([type(k) == tuple and len(k) == 2 for k in high_corr.keys()]),\\\n",
       "        AttributeError: 'list' object has no attribute 'keys'\n",
       "</pre><p><strong><pre style='display: inline;'>q3.1 - 3</pre> result:</strong></p><pre>    Trying:\n",
       "        assert all([np.issubdtype(v, np.float_) and v >= -1 and v <= 1for v in high_corr.values()]),\\\n",
       "        \"values of high_corr should be floats between -1 and 1 (inclusive).\"\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 1, in q3.1 2\n",
       "    Failed example:\n",
       "        assert all([np.issubdtype(v, np.float_) and v >= -1 and v <= 1for v in high_corr.values()]),\\\n",
       "        \"values of high_corr should be floats between -1 and 1 (inclusive).\"\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/Users/karenkuo/opt/anaconda3/lib/python3.9/doctest.py\", line 1334, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q3.1 2[0]>\", line 1, in <module>\n",
       "            assert all([np.issubdtype(v, np.float_) and v >= -1 and v <= 1for v in high_corr.values()]),\\\n",
       "        AttributeError: 'list' object has no attribute 'values'\n",
       "</pre>"
      ],
      "text/plain": [
       "q3.1 results:\n",
       "    q3.1 - 1 result:\n",
       "        Trying:\n",
       "            assert type(high_corr) == dict and len(high_corr) == 9,\\\n",
       "            \"high_corr should be a dict with 9 entries\"\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q3.1 0\n",
       "        Failed example:\n",
       "            assert type(high_corr) == dict and len(high_corr) == 9,\\\n",
       "            \"high_corr should be a dict with 9 entries\"\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/Users/karenkuo/opt/anaconda3/lib/python3.9/doctest.py\", line 1334, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q3.1 0[0]>\", line 1, in <module>\n",
       "                assert type(high_corr) == dict and len(high_corr) == 9,\\\n",
       "            AssertionError: high_corr should be a dict with 9 entries\n",
       "\n",
       "    q3.1 - 2 result:\n",
       "        Trying:\n",
       "            assert all([type(k) == tuple and len(k) == 2 for k in high_corr.keys()]),\\\n",
       "            \"keys of high_corr should be tuples of length 2\"\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q3.1 1\n",
       "        Failed example:\n",
       "            assert all([type(k) == tuple and len(k) == 2 for k in high_corr.keys()]),\\\n",
       "            \"keys of high_corr should be tuples of length 2\"\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/Users/karenkuo/opt/anaconda3/lib/python3.9/doctest.py\", line 1334, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q3.1 1[0]>\", line 1, in <module>\n",
       "                assert all([type(k) == tuple and len(k) == 2 for k in high_corr.keys()]),\\\n",
       "            AttributeError: 'list' object has no attribute 'keys'\n",
       "\n",
       "    q3.1 - 3 result:\n",
       "        Trying:\n",
       "            assert all([np.issubdtype(v, np.float_) and v >= -1 and v <= 1for v in high_corr.values()]),\\\n",
       "            \"values of high_corr should be floats between -1 and 1 (inclusive).\"\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q3.1 2\n",
       "        Failed example:\n",
       "            assert all([np.issubdtype(v, np.float_) and v >= -1 and v <= 1for v in high_corr.values()]),\\\n",
       "            \"values of high_corr should be floats between -1 and 1 (inclusive).\"\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/Users/karenkuo/opt/anaconda3/lib/python3.9/doctest.py\", line 1334, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q3.1 2[0]>\", line 1, in <module>\n",
       "                assert all([np.issubdtype(v, np.float_) and v >= -1 and v <= 1for v in high_corr.values()]),\\\n",
       "            AttributeError: 'list' object has no attribute 'values'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9427956f",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**3.2** Fit a linear regression model on the **unscaled** training data **using all available predictors**. Store the train and test $R^2$ scores in `linreg_train_r2` and `linreg_test_r2` respectively. Interpret your results.\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "febca240-f6b4-4658-9511-922bfbb78ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# householdsize: mean people per household\n",
    "# medIncome: median household income\n",
    "# PctHousOccup: percent of housing occupied\n",
    "# RentMedian: rental housing - median rent\n",
    "# PolicReqPerOffic: total requests for police per police officer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acedd7f",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "868c4195",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear regression train R^2: 0.8461\n",
      "linear regression test R^2: 0.2186\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "linreg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "linreg_train_r2 = linreg.score(X_train, y_train)\n",
    "linreg_test_r2 = linreg.score(X_test, y_test)\n",
    "print(f\"linear regression train R^2: {linreg_train_r2:.4f}\")\n",
    "print(f\"linear regression test R^2: {linreg_test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b0a2b4df",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3.2</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q3.2 results: All test cases passed!"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387f193e",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "\n",
    "**3.3.1** Standardize both **X_train** and **X_test**, *fitting the scaler on all the data*, and for each number of components $k$ in $k \\in \\{1,2,3,4,5,6,8,10,12,15,20\\}$: \n",
    "\n",
    "  - Fit the PCA transformation with n_components = $k$ on the standardized **X_train**.\n",
    "    \n",
    "  - Apply the PCA transformation to the standardized **X_train**.\n",
    "    \n",
    "  - Use scikit-learn's cross_validate(...) to perform a 10-fold cross validation for a linear regression model on the transformed training data. \n",
    "    \n",
    "  Plot the mean validation MSE for each $k$. Store the best $k$ based on the mean validation MSE as `best_k`.\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "50c1855b-2f5b-4a3c-8500-459e036fcc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(np.concatenate([X_train.values, X_test.values], axis=0))\n",
    "X_train_scaled = scaler.transform(X_train.values)\n",
    "X_test_scaled = scaler.transform(X_test.values)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0ffbe2d2-edd3-4d2a-92a9-5646f54aca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [1,2,3,4,5,6,8,10,12,15,20]\n",
    "cross_validation_error = []\n",
    "\n",
    "for k in ks:\n",
    "    pca = PCA(n_components=k).fit(X_train_scaled)\n",
    "    X_train_pca = pca.transform(X_train_scaled)\n",
    "    \n",
    "    lreg = LinearRegression().fit(X_train_pca, y_train)\n",
    "\n",
    "    cv = cross_validate(lreg, X_train_pca[:,:k+1], y_train, scoring =('neg_mean_squared_error'),\n",
    "                        cv=10, return_train_score=True)\n",
    "    cross_validation_error.append(cv['test_score'].mean()*-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "236dc438",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best k is 7.\n"
     ]
    }
   ],
   "source": [
    "best_k = np.argmin(cross_validation_error)+1\n",
    "print(f\"The best k is {best_k}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8e79e495",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3.3.1</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q3.3.1 results: All test cases passed!"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3.3.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02c6160",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "    \n",
    "\n",
    "**3.3.2** Now let's compute the $R^2$ value on the testing data:\n",
    "  - Fit the PCA transformation on the standardized **X_train** with n_components equal to the best $k$ above.\n",
    "  - Apply the PCA transformation to the standardized **X_train** and the standardized **X_test**. \n",
    "  - Fit a linear regression model to the PCA-transformed components. Store the train and test $R^2$ scores in `pcr_train_r2` and `pcr_test_r2` respectively.\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "dbd1048a-c02e-472f-9cad-abed65d7822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "778e5434-1f11-47b8-ab9e-2565c80e3f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_train_bestk = PCA(n_components = best_k).fit(X_train_scaled)\n",
    "X_train_pca_bestk = pca_train_bestk.transform(X_train_scaled)\n",
    "\n",
    "pca_test_bestk = PCA(n_components = best_k).fit(X_test_std)\n",
    "X_test_pca_bestk = pca_test_bestk.transform(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "64407054-01d5-4207-a1ea-8e3fec9449e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg_bestk = LinearRegression().fit(X_train_pca_bestk, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "22ecc46e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCR train R^2: 0.6016\n",
      "PCR test R^2: -1.4440\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "pcr_train_r2 = lreg_bestk.score(X_train_pca_bestk, y_train)\n",
    "pcr_test_r2 = lreg_bestk.score(X_test_pca_bestk, y_test)\n",
    "print(f\"PCR train R^2: {pcr_train_r2:.4f}\")\n",
    "print(f\"PCR test R^2: {pcr_test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "0dabf0ea",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>q3.3.2</pre> results:</strong></p><p><strong><pre style='display: inline;'>q3.3.2 - 1</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q3.3.2 - 2</pre> result:</strong></p><pre>    Trying:\n",
       "        assert pcr_test_r2 > 0.2 and pcr_test_r2 < 0.8,\\\n",
       "        \"The true pcr_test_r2 is between 0.2 and 0.8\"\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 1, in q3.3.2 1\n",
       "    Failed example:\n",
       "        assert pcr_test_r2 > 0.2 and pcr_test_r2 < 0.8,\\\n",
       "        \"The true pcr_test_r2 is between 0.2 and 0.8\"\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/Users/karenkuo/opt/anaconda3/lib/python3.9/doctest.py\", line 1334, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q3.3.2 1[0]>\", line 1, in <module>\n",
       "            assert pcr_test_r2 > 0.2 and pcr_test_r2 < 0.8,\\\n",
       "        AssertionError: The true pcr_test_r2 is between 0.2 and 0.8\n",
       "</pre>"
      ],
      "text/plain": [
       "q3.3.2 results:\n",
       "    q3.3.2 - 1 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q3.3.2 - 2 result:\n",
       "        Trying:\n",
       "            assert pcr_test_r2 > 0.2 and pcr_test_r2 < 0.8,\\\n",
       "            \"The true pcr_test_r2 is between 0.2 and 0.8\"\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q3.3.2 1\n",
       "        Failed example:\n",
       "            assert pcr_test_r2 > 0.2 and pcr_test_r2 < 0.8,\\\n",
       "            \"The true pcr_test_r2 is between 0.2 and 0.8\"\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/Users/karenkuo/opt/anaconda3/lib/python3.9/doctest.py\", line 1334, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q3.3.2 1[0]>\", line 1, in <module>\n",
       "                assert pcr_test_r2 > 0.2 and pcr_test_r2 < 0.8,\\\n",
       "            AssertionError: The true pcr_test_r2 is between 0.2 and 0.8"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3.3.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a764d7d0",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**3.4** Compare the $R^2$ value obtained from **3.2** (original predictors) and **3.3.2** (PCR). Provide an explanation for the observed difference in these results.\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a279488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display your results\n",
    "pd.DataFrame([\n",
    "    {'model': 'linear regression (original predictors)',\n",
    "     'train $R^2$': linreg_train_r2,\n",
    "     'test $R^2$': linreg_test_r2},\n",
    "    {'model': f'PCR (k={best_k})',\n",
    "     'train $R^2$': pcr_train_r2,\n",
    "     'test $R^2$': pcr_test_r2},\n",
    "]).set_index('model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81d4cee",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a61b4af",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<a id=\"part2q4\"></a>\n",
    "\n",
    "## <div class='exercise'><b> Question 4: Visualizing Transformed Data [10 pts]</b></div>\n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "In this question, we will be using a dataset called \"Better Life Index\" adapted from [Organisation for Economic Co-operation and Development](https://stats.oecd.org/). The modified dataset contains 24 numerical variables and 1 categorical variable. The categorical variable `Country` is the name of the country. Some of the numerical variables include:\n",
    "\n",
    "- `Dwellings without basic facilities`\n",
    "- `Housing expenditure`\n",
    "- `Rooms per person`\n",
    "- `Household net adjusted disposable income`\n",
    "- `Household net financial wealth`\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e2304c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (38, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Dwellings without basic facilities</th>\n",
       "      <th>Housing expenditure</th>\n",
       "      <th>Rooms per person</th>\n",
       "      <th>Household net adjusted disposable income</th>\n",
       "      <th>Household net financial wealth</th>\n",
       "      <th>Labour market insecurity</th>\n",
       "      <th>Employment rate</th>\n",
       "      <th>Long-term unemployment rate</th>\n",
       "      <th>Personal earnings</th>\n",
       "      <th>Quality of support network</th>\n",
       "      <th>Educational attainment</th>\n",
       "      <th>Student skills</th>\n",
       "      <th>Years in education</th>\n",
       "      <th>Air pollution</th>\n",
       "      <th>Water quality</th>\n",
       "      <th>Stakeholder engagement for developing regulations</th>\n",
       "      <th>Voter turnout</th>\n",
       "      <th>Life expectancy</th>\n",
       "      <th>Self-reported health</th>\n",
       "      <th>Life satisfaction</th>\n",
       "      <th>Feeling safe walking alone at night</th>\n",
       "      <th>Homicide rate</th>\n",
       "      <th>Employees working very long hours</th>\n",
       "      <th>Time devoted to leisure and personal care</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>1.1</td>\n",
       "      <td>20</td>\n",
       "      <td>2.3</td>\n",
       "      <td>33417</td>\n",
       "      <td>57462</td>\n",
       "      <td>4.3</td>\n",
       "      <td>72</td>\n",
       "      <td>1.36</td>\n",
       "      <td>52063</td>\n",
       "      <td>94</td>\n",
       "      <td>80</td>\n",
       "      <td>502</td>\n",
       "      <td>21.2</td>\n",
       "      <td>5</td>\n",
       "      <td>92</td>\n",
       "      <td>2.7</td>\n",
       "      <td>91</td>\n",
       "      <td>82.5</td>\n",
       "      <td>85</td>\n",
       "      <td>7.3</td>\n",
       "      <td>63.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.20</td>\n",
       "      <td>14.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Austria</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21</td>\n",
       "      <td>1.6</td>\n",
       "      <td>32544</td>\n",
       "      <td>59574</td>\n",
       "      <td>2.7</td>\n",
       "      <td>72</td>\n",
       "      <td>1.94</td>\n",
       "      <td>48295</td>\n",
       "      <td>92</td>\n",
       "      <td>85</td>\n",
       "      <td>492</td>\n",
       "      <td>17.1</td>\n",
       "      <td>16</td>\n",
       "      <td>93</td>\n",
       "      <td>1.3</td>\n",
       "      <td>75</td>\n",
       "      <td>81.3</td>\n",
       "      <td>70</td>\n",
       "      <td>7.0</td>\n",
       "      <td>80.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>6.78</td>\n",
       "      <td>14.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Belgium</td>\n",
       "      <td>2.3</td>\n",
       "      <td>21</td>\n",
       "      <td>2.2</td>\n",
       "      <td>29968</td>\n",
       "      <td>104084</td>\n",
       "      <td>4.8</td>\n",
       "      <td>62</td>\n",
       "      <td>3.98</td>\n",
       "      <td>49587</td>\n",
       "      <td>92</td>\n",
       "      <td>75</td>\n",
       "      <td>503</td>\n",
       "      <td>18.2</td>\n",
       "      <td>15</td>\n",
       "      <td>84</td>\n",
       "      <td>2.2</td>\n",
       "      <td>89</td>\n",
       "      <td>81.1</td>\n",
       "      <td>75</td>\n",
       "      <td>6.9</td>\n",
       "      <td>70.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.31</td>\n",
       "      <td>15.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Canada</td>\n",
       "      <td>0.2</td>\n",
       "      <td>22</td>\n",
       "      <td>2.5</td>\n",
       "      <td>29850</td>\n",
       "      <td>85758</td>\n",
       "      <td>3.9</td>\n",
       "      <td>73</td>\n",
       "      <td>0.81</td>\n",
       "      <td>48403</td>\n",
       "      <td>93</td>\n",
       "      <td>91</td>\n",
       "      <td>523</td>\n",
       "      <td>16.7</td>\n",
       "      <td>7</td>\n",
       "      <td>91</td>\n",
       "      <td>3.0</td>\n",
       "      <td>68</td>\n",
       "      <td>81.5</td>\n",
       "      <td>88</td>\n",
       "      <td>7.3</td>\n",
       "      <td>80.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.73</td>\n",
       "      <td>14.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chile</td>\n",
       "      <td>9.4</td>\n",
       "      <td>18</td>\n",
       "      <td>1.9</td>\n",
       "      <td>16588</td>\n",
       "      <td>21409</td>\n",
       "      <td>8.1</td>\n",
       "      <td>62</td>\n",
       "      <td>2.02</td>\n",
       "      <td>28434</td>\n",
       "      <td>84</td>\n",
       "      <td>65</td>\n",
       "      <td>443</td>\n",
       "      <td>17.3</td>\n",
       "      <td>16</td>\n",
       "      <td>69</td>\n",
       "      <td>1.5</td>\n",
       "      <td>49</td>\n",
       "      <td>79.1</td>\n",
       "      <td>57</td>\n",
       "      <td>6.7</td>\n",
       "      <td>51.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>10.06</td>\n",
       "      <td>14.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country  Dwellings without basic facilities  Housing expenditure  \\\n",
       "0  Australia                                 1.1                   20   \n",
       "1    Austria                                 1.0                   21   \n",
       "2    Belgium                                 2.3                   21   \n",
       "3     Canada                                 0.2                   22   \n",
       "4      Chile                                 9.4                   18   \n",
       "\n",
       "   Rooms per person  Household net adjusted disposable income  \\\n",
       "0               2.3                                     33417   \n",
       "1               1.6                                     32544   \n",
       "2               2.2                                     29968   \n",
       "3               2.5                                     29850   \n",
       "4               1.9                                     16588   \n",
       "\n",
       "   Household net financial wealth  Labour market insecurity  Employment rate  \\\n",
       "0                           57462                       4.3               72   \n",
       "1                           59574                       2.7               72   \n",
       "2                          104084                       4.8               62   \n",
       "3                           85758                       3.9               73   \n",
       "4                           21409                       8.1               62   \n",
       "\n",
       "   Long-term unemployment rate  Personal earnings  Quality of support network  \\\n",
       "0                         1.36              52063                          94   \n",
       "1                         1.94              48295                          92   \n",
       "2                         3.98              49587                          92   \n",
       "3                         0.81              48403                          93   \n",
       "4                         2.02              28434                          84   \n",
       "\n",
       "   Educational attainment  Student skills  Years in education  Air pollution  \\\n",
       "0                      80             502                21.2              5   \n",
       "1                      85             492                17.1             16   \n",
       "2                      75             503                18.2             15   \n",
       "3                      91             523                16.7              7   \n",
       "4                      65             443                17.3             16   \n",
       "\n",
       "   Water quality  Stakeholder engagement for developing regulations  \\\n",
       "0             92                                                2.7   \n",
       "1             93                                                1.3   \n",
       "2             84                                                2.2   \n",
       "3             91                                                3.0   \n",
       "4             69                                                1.5   \n",
       "\n",
       "   Voter turnout  Life expectancy  Self-reported health  Life satisfaction  \\\n",
       "0             91             82.5                    85                7.3   \n",
       "1             75             81.3                    70                7.0   \n",
       "2             89             81.1                    75                6.9   \n",
       "3             68             81.5                    88                7.3   \n",
       "4             49             79.1                    57                6.7   \n",
       "\n",
       "   Feeling safe walking alone at night  Homicide rate  \\\n",
       "0                                 63.6            1.0   \n",
       "1                                 80.7            0.4   \n",
       "2                                 70.7            1.0   \n",
       "3                                 80.9            1.4   \n",
       "4                                 51.1            4.5   \n",
       "\n",
       "   Employees working very long hours  \\\n",
       "0                              13.20   \n",
       "1                               6.78   \n",
       "2                               4.31   \n",
       "3                               3.73   \n",
       "4                              10.06   \n",
       "\n",
       "   Time devoted to leisure and personal care  \n",
       "0                                      14.35  \n",
       "1                                      14.55  \n",
       "2                                      15.77  \n",
       "3                                      14.41  \n",
       "4                                      14.90  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and inspect the datasets\n",
    "df = pd.read_csv(\"data/OECD_well-being.csv\", index_col = 0)\n",
    "print('df shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "983d396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate predictors and response\n",
    "country, X = df['Country'], df.drop(columns='Country').values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10f9264",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**4.1** Standardize **X** and apply a PCA transformation with n_components = 2 to your standardized data. Save the transformed data as `X_transformed`.\n",
    "    \n",
    "</div>\n",
    "\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f65835f1-e7f4-4a42-8191-c45988adb39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X)\n",
    "X_std = scaler.transform(X)\n",
    "\n",
    "pca = PCA().fit(X_std)\n",
    "X_pca = pca.transform(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc5565c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "X_transformed = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c966f9f1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742a35ae",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**4.2** Make a scatter plot for the transformed data, where the x-axis corresponds to the first principal component, and the y-axis corresponds to the second principal component. The plot should state the amount of variance explained by each component. \n",
    "\n",
    "Label each point by its corresponding country name. Do you observe any pattern in the scatter plot? Be specific and explain.\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeea3f5a",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892df33a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4822f83",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**4.3** In question 3, where we also used PCA, we had a training and a test set. In question 4 we did not split the data. Explain why.\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66ac4a0",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0861e990",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**This concludes HW4. Thank you!**\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1.1": {
     "name": "q1.1",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_n_rows_with_missingness():\n...     assert np.issubdtype(n_rows_with_missingness, np.integer), \"n_rows_with_missingness should be an integer\" \n...     assert n_rows_with_missingness >=0, \"n_rows_with_missingness should be non-negative\" \n>>> test_n_rows_with_missingness()\n",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> def test_n_cols_with_missingness():\n...     assert np.issubdtype(n_cols_with_missingness, np.integer), \"n_cols_with_missingness should be an integer\" \n...     assert n_cols_with_missingness >=0, \"n_cols_with_missingness should be non-negative\" \n>>> test_n_cols_with_missingness()\n",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> def test_col_missingness():\n...     col_missingness_sol = X_train.isna().sum(axis=0)\n...     assert type(col_missingness) == pd.Series, \"col_missingness should be a Pandas Series object\"\n...     assert all([type(i) == str for i in col_missingness.index]), \"Indices of col_missingness should be strings (i.e., the column names)\"\n...     assert set(col_missingness.index) == set(X_train.columns), \"Indices of col_missingness shoudl be the names of the X_train columns.\"\n...     assert all([np.issubdtype(v, np.integer) for v in col_missingness.values]), \"Values in col_missingness should be some type of integer\"\n>>> test_col_missingness()\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.1": {
     "name": "q2.1",
     "points": 12,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert linreg_meanimp_r2 > 0.1 and linreg_meanimp_r2 < 0.2,\\\n... \"The true linreg_meanimp_r2 is between 0.1 and 0.2\"\n",
         "hidden": false,
         "locked": false,
         "points": 3
        },
        {
         "code": ">>> assert knn_meanimp_r2 > 0.35 and knn_meanimp_r2 < 0.45,\\\n... \"The true knn_meanimp_r2 is between 0.35 and 0.45\"\n",
         "hidden": false,
         "locked": false,
         "points": 3
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.2": {
     "name": "q2.2",
     "points": 12,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert linreg_knnimp_r2 > 0.2 and linreg_meanimp_r2 < 0.3,\\\n... \"The true linreg_knnimp_r2 is between 0.2 and 0.3\"\n",
         "hidden": false,
         "locked": false,
         "points": 3
        },
        {
         "code": ">>> assert knn_knnimp_r2 > 0.55 and knn_knnimp_r2 < 0.65,\\\n... \"The true knn_knnimp_r2 is between 0.55 and 0.65\"\n",
         "hidden": false,
         "locked": false,
         "points": 3
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.3": {
     "name": "q2.3",
     "points": 12,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert linreg_indic_r2 > 0.2 and linreg_indic_r2 < 0.5,\\\n... \"The true linreg_indic_r2 is between 0.2 and 0.5\"\n",
         "hidden": false,
         "locked": false,
         "points": 3
        },
        {
         "code": ">>> assert knn_indic_r2 > 0.55 and knn_indic_r2 < 0.75,\\\n... \"The true knn_indic_r2 is between 0.55 and 0.75\"\n",
         "hidden": false,
         "locked": false,
         "points": 3
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.1": {
     "name": "q3.1",
     "points": 6,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert type(high_corr) == dict and len(high_corr) == 9,\\\n... \"high_corr should be a dict with 9 entries\"\n",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> assert all([type(k) == tuple and len(k) == 2 for k in high_corr.keys()]),\\\n... \"keys of high_corr should be tuples of length 2\"\n",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> assert all([np.issubdtype(v, np.float_) and v >= -1 and v <= 1for v in high_corr.values()]),\\\n... \"values of high_corr should be floats between -1 and 1 (inclusive).\"\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.2": {
     "name": "q3.2",
     "points": 6,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert linreg_train_r2 > 0.1 and linreg_train_r2 < 0.9,\\\n... \"The true linreg_train_r2 is between 0.1 and 0.9\"\n",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> assert linreg_test_r2 > 0.1 and linreg_test_r2 < 0.9,\\\n... \"The true linreg_test_r2 is between 0.1 and 0.9\"\n",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.3.1": {
     "name": "q3.3.1",
     "points": 14,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert best_k > 4 and best_k < 15,\\\n... \"The true best_k is between 4 and 15\"\n",
         "hidden": false,
         "locked": false,
         "points": 2
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.3.2": {
     "name": "q3.3.2",
     "points": 6,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert pcr_train_r2 > 0.2 and pcr_train_r2 < 0.8,\\\n... \"The true pcr_train_r2 is between 0.2 and 0.8\"\n",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> assert pcr_test_r2 > 0.2 and pcr_test_r2 < 0.8,\\\n... \"The true pcr_test_r2 is between 0.2 and 0.8\"\n",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4.1": {
     "name": "q4.1",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert X_transformed.shape == (38, 2),\\\n... \"The transformed data should have shape (38, 2).\"\n",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> assert np.isclose(X_transformed.mean(), 0),\\\n... \"The mean of the transformed data should be 0 (or very close given machine precision).\"\n",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
