{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"cs109a_hw5.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109A Introduction to Data Science: \n",
    "## Homework 5: Predicting College Admissions\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2022**<br/>\n",
    "**Instructors**: Pavlos Protopapas, Natesh Pillai\n",
    "\n",
    "<hr style=\"height:2.4pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 {\n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left;\n",
       "    padding-left: 10px;\n",
       "    background-color: #63ACBE;\n",
       "    color: black;\n",
       "}\n",
       "h2 {\n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left;\n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE;\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #f8b4ab;\n",
       "\tborder-color: #E9967A;\n",
       "\tborder-left: 5px solid #601A4A;\n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "div.exercise-r {\n",
       "\tbackground-color: #ffd0d0;\n",
       "\tborder-color: #E9967A;\n",
       "\tborder-left: 5px solid #601A4A;\n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "\n",
       "span.sub-q {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #63ACBE;\n",
       "\tborder-color: #E9967A;\n",
       "\tborder-left: 5px solid #601A4A;\n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc {\n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A;\n",
       "\tborder-left: 5px solid #601A4A;\n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 {\n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left;\n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE;\n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left;\n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD;\n",
       "    color: black;\n",
       "}\n",
       "span.emph {\n",
       "\tcolor: #601A4A;\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\n",
    "    \"https://raw.githubusercontent.com/Harvard-IACS/2021-CS109A/master/\"\n",
    "    \"themes/static/css/cs109.css\"\n",
    ").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# pandas tricks for better display\n",
    "pd.options.display.max_columns = 50  \n",
    "pd.options.display.max_rows = 500     \n",
    "pd.options.display.max_colwidth = 100\n",
    "pd.options.display.precision = 3\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions\n",
    "- To submit your assignment follow the instructions given in Canvas.\n",
    "- Plots should be legible and interpretable without having to refer to the code that generated them, including labels for the $x$- and $y$-axes as well as a descriptive title and/or legend when appropriate.\n",
    "- When asked to interpret a visualization, do not simply describe it (e.g., \"the curve has a steep slope up\"), but instead explain what you think the plot *means*.\n",
    "- The use of 'hard-coded' values to try and pass tests rather than solving problems programmatically will not receive credit.\n",
    "- The use of *extremely* inefficient or error-prone code (e.g., copy-pasting nearly identical commands rather than looping) may result in only partial credit.\n",
    "- We have tried to include all the libraries you may need to do the assignment in the imports cell provided below. Please get course staff approval before importing any additional 3rd party libraries.\n",
    "- Enable scrolling output on cells with very long output.\n",
    "- Feel free to add additional code or markdown cells as needed.\n",
    "- Ensure your code runs top to bottom without error and passes all tests by restarting the kernel and running all cells. This is how the notebook will be evaluated (note that this can take a few minutes). \n",
    "- **You should do a \"Restart Kernel and Run All Cells\" before submitting to ensure (1) your notebook actually runs and (2) all output is visible**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"contents\"></a>\n",
    "\n",
    "## Notebook contents\n",
    "\n",
    "- [**Overview and data description**](#intro)\n",
    "\n",
    "\n",
    "- [**Question 1: Data exploration using train and basic models [16 pts]**](#part1)\n",
    "\n",
    "- [**Question 2: Interpretable modeling [18 pts]**](#part2)\n",
    "\n",
    "- [**Question 3: Harvard and Yale? [30 pts]**](#part3)\n",
    "\n",
    "- [**Question 4: Building predictive models for admitted [24 pts]**](#part4)\n",
    "\n",
    "- [**Question 5: Evaluating results [12 pts]**](#part5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "\n",
    "## Overview and data description\n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "### Predicting admissions into elite universities\n",
    "\n",
    "In this problem set we will model the chances of high school students being accepted into two different elite undergraduate colleges (one is elite at least :) ): Harvard and Yale.  The data are provided in the file `data/college_admissions.csv` and were scraped from [collegedata.com](https://www.collegedata.com/) (where applicants volunteer to share their information).  Each observation corresponds to an applicant to one of the two different colleges (note: the same applicant may show up in two rows: once for each college).  The main response is the `\"admitted\"` variable (1 = admitted, 0 = denied), and there are are several predictors to consider:\n",
    "\n",
    "- **id**: a unique identifier for the applicant \n",
    "- **test_score**: a standardized measurement of the applicant's highest ACT or SAT combined score (2400 is the maximum)\n",
    "- **ap**: the number of AP tests taken\n",
    "- **avg_ap**: the average score on the AP tests taken (0 if no tests were taken)\n",
    "- **sat_subjects**: the number of SAT subject tests taken\n",
    "- **gpa**: the unweighted GPA of the applicant (max of 4.0)\n",
    "- **female**:  a binary indicator for gender: 1 = female, 0 = otherwise\n",
    "- **minority**: a binary indicator for under-represented minority: 1 = minority, 0 = otherwise \n",
    "- **international**: a binary indicator for international status: 1 = international, 0 = United States\n",
    "- **sports**: a binary indicator for High School All-American: 1 = all-American athlete, 0 = otherwise\n",
    "- **school**: a categorical variable for school applied to: \"Harvard\" or \"Yale\"\n",
    "- **early_app**: a binary indicator for application type: 1 = early action, 0 = regular\n",
    "- **alumni**:  a binary indicator for parents' alumni status of school: 1 = a parent is an alumnus, 0 = otherwise\n",
    "- **program**: the program applied to by the student with many choices (we will not use this as a predictor)\n",
    "- **add_info**: additional (optional) info provided by applicant (we will not use this as a predictor)\n",
    "\n",
    "**The main set of 12 predictors is:**\n",
    "\n",
    "```python\n",
    "[\n",
    "    \"test_score\", \"ap\", \"avg_ap\", \"sat_subjects\", \n",
    "    \"gpa\", \"female\", \"minority\", \"international\",\n",
    "    \"sports\", \"school\", \"early_app\", \"alumni\",\n",
    "]\n",
    "```\n",
    "\n",
    "Please note, you may need to modify this list when fitting different models, and you will be replacing the `\"school\"` variable with a binary `\"harvard\"` variable early in the questions below.\n",
    "\n",
    "\n",
    "**IMPORTANT NOTES:**\n",
    "\n",
    "- Unless stated otherwise, all logistic regression models should be unregularized (use `penalty=\"none\"`) and include the intercept (which is the default in `sklearn`).\n",
    "\n",
    "\n",
    "- When printing your output (e.g. coefficients, accuracy scores, etc.), DO NOT just print numbers without context. Please be certain provide clarifying labels for all printed numbers and limit the number of digits showing after decimals to a reasonable length (e.g. 4 decimal points for coefficients and accuracy scores).\n",
    "\n",
    "\n",
    "- Also be sure to practice good data science principles: always use train to do analysis and never touch the test set until the very end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part1\"></a>\n",
    "\n",
    "## <div class='exercise'>Question 1: Data exploration using train and basic models [16 pts]</div>\n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "The first step is to split the observations into an approximate 80-20 train-test split.  Below is some code to do this for you (we want to make sure everyone has the same splits). It also prints the dataset's shape before splitting and after splitting. \n",
    "\n",
    "**IMPORTANT:** While an argument could be made to scale our predictors here, please **DO NOT** do so **UNTIL** it is requested of you in **[Question 4.1](#part4)**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1871, 16)\n",
      "(1496, 16) (375, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>admitted</th>\n",
       "      <th>test_score</th>\n",
       "      <th>ap</th>\n",
       "      <th>avg_ap</th>\n",
       "      <th>sat_subjects</th>\n",
       "      <th>gpa</th>\n",
       "      <th>female</th>\n",
       "      <th>minority</th>\n",
       "      <th>international</th>\n",
       "      <th>sports</th>\n",
       "      <th>school</th>\n",
       "      <th>early_app</th>\n",
       "      <th>alumni</th>\n",
       "      <th>program</th>\n",
       "      <th>add_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>JTEQOV7ZCB</td>\n",
       "      <td>0</td>\n",
       "      <td>2080</td>\n",
       "      <td>5</td>\n",
       "      <td>4.400</td>\n",
       "      <td>4</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Harvard</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Mechanical Engineering</td>\n",
       "      <td>Swimming 3 years Water Polo 3 years Foreign Language Honor Society PresidentMerit award in Socia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>I03PV24OHY</td>\n",
       "      <td>1</td>\n",
       "      <td>2190</td>\n",
       "      <td>6</td>\n",
       "      <td>3.667</td>\n",
       "      <td>3</td>\n",
       "      <td>3.97</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yale</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>legal studies</td>\n",
       "      <td>horseback riding 5 hrs week year round marching concert jazz and orchestral ensembles 30 hrs wee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>K42SAOUYJJ</td>\n",
       "      <td>0</td>\n",
       "      <td>2140</td>\n",
       "      <td>2</td>\n",
       "      <td>4.500</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yale</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Film</td>\n",
       "      <td>Lacrosse Film Club Take Action Club NYU Tisch Summer Film WorkshopNational Honors Society World ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>LODYYSRTYZ</td>\n",
       "      <td>0</td>\n",
       "      <td>2120</td>\n",
       "      <td>6</td>\n",
       "      <td>3.333</td>\n",
       "      <td>3</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yale</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Biological Sciences</td>\n",
       "      <td>Varsity Orchestra Music Librarian 10 11 12 Violin Player Girl Scouts 10 year Member sold over 65...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OC717EAKXN</td>\n",
       "      <td>1</td>\n",
       "      <td>2400</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000</td>\n",
       "      <td>5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Harvard</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  admitted  test_score  ap  avg_ap  sat_subjects   gpa  \\\n",
       "584   JTEQOV7ZCB         0        2080   5   4.400             4  3.90   \n",
       "1817  I03PV24OHY         1        2190   6   3.667             3  3.97   \n",
       "1308  K42SAOUYJJ         0        2140   2   4.500             3  3.70   \n",
       "1336  LODYYSRTYZ         0        2120   6   3.333             3  4.00   \n",
       "3     OC717EAKXN         1        2400   5   5.000             5  4.00   \n",
       "\n",
       "      female  minority  international  sports   school  early_app  alumni  \\\n",
       "584        1         0              0       0  Harvard          1       0   \n",
       "1817       1         0              0       0     Yale          0       0   \n",
       "1308       0         0              0       0     Yale          0       0   \n",
       "1336       1         0              0       0     Yale          1       0   \n",
       "3          1         0              0       0  Harvard          0       0   \n",
       "\n",
       "                     program  \\\n",
       "584   Mechanical Engineering   \n",
       "1817           legal studies   \n",
       "1308                    Film   \n",
       "1336     Biological Sciences   \n",
       "3                Mathematics   \n",
       "\n",
       "                                                                                                 add_info  \n",
       "584   Swimming 3 years Water Polo 3 years Foreign Language Honor Society PresidentMerit award in Socia...  \n",
       "1817  horseback riding 5 hrs week year round marching concert jazz and orchestral ensembles 30 hrs wee...  \n",
       "1308  Lacrosse Film Club Take Action Club NYU Tisch Summer Film WorkshopNational Honors Society World ...  \n",
       "1336  Varsity Orchestra Music Librarian 10 11 12 Violin Player Girl Scouts 10 year Member sold over 65...  \n",
       "3                                                                                                     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1496 entries, 584 to 1537\n",
      "Data columns (total 16 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             1496 non-null   object \n",
      " 1   admitted       1496 non-null   int64  \n",
      " 2   test_score     1496 non-null   int64  \n",
      " 3   ap             1496 non-null   int64  \n",
      " 4   avg_ap         1496 non-null   float64\n",
      " 5   sat_subjects   1496 non-null   int64  \n",
      " 6   gpa            1496 non-null   float64\n",
      " 7   female         1496 non-null   int64  \n",
      " 8   minority       1496 non-null   int64  \n",
      " 9   international  1496 non-null   int64  \n",
      " 10  sports         1496 non-null   int64  \n",
      " 11  school         1496 non-null   object \n",
      " 12  early_app      1496 non-null   int64  \n",
      " 13  alumni         1496 non-null   int64  \n",
      " 14  program        1294 non-null   object \n",
      " 15  add_info       933 non-null    object \n",
      "dtypes: float64(2), int64(10), object(4)\n",
      "memory usage: 198.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "## DO NOT MODIFY THIS CODE ##\n",
    "#############################\n",
    "\n",
    "college = pd.read_csv(\"data/college_admissions.csv\")\n",
    "np.random.seed(121)\n",
    "\n",
    "college_train, college_test = train_test_split(\n",
    "    college,\n",
    "    test_size=0.2,\n",
    "    random_state=121,\n",
    "    shuffle=True,\n",
    "    stratify=college[\"school\"],\n",
    ")\n",
    "\n",
    "print(college.shape)\n",
    "print(college_train.shape, college_test.shape)\n",
    "display(college_train.head())\n",
    "college_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**Q1.1** Calculate the proportion of observations in the train data that were admitted and store this value in `prop_admitted_train`.  What would be the train and test classification accuracies for a baseline \"naive\" model where we classified *ALL* applicants as either admitted or not admitted using just this overall proportion to make our decision (i.e. we apply the same outcome to all applicants based on this proportion)? Store these classification accuracies in `naive_train_acc` and `naive_test_acc`.\n",
    "    \n",
    "**NOTE:** For this assignment, use the convention that accuracies range from 0 to 1 (to be consistant with sklearn).\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "train_admitted = len([i for i in college_train['admitted'] if i==1])\n",
    "prop_admitted_train = train_admitted / (len(college_train['admitted']))\n",
    "\n",
    "test_admitted = len([i for i in college_test['admitted'] if i==1])\n",
    "prop_admitted_test = test_admitted / (len(college_test['admitted']))\n",
    "\n",
    "naive_train_acc = prop_admitted_train\n",
    "naive_test_acc = prop_admitted_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion Admitted in training Data: 0.26\n",
      "Naive Classification Model Based on Training Proportions\n",
      "\tTrain Accuracy: 0.26\n",
      "\tTest Accuracy: 0.30\n"
     ]
    }
   ],
   "source": [
    "print(f\"Proportion Admitted in training Data: {prop_admitted_train:.2f}\")\n",
    "print(\"Naive Classification Model Based on Training Proportions\")\n",
    "print(f\"\\tTrain Accuracy: {naive_train_acc:.2f}\")\n",
    "print(f\"\\tTest Accuracy: {naive_test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1.1</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q1.1 results: All test cases passed!"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "self._engine.get_loc(casted_key)<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**Q1.2** Create a binary (\"dummy\") variable named `\"harvard\"` in both the train and test DataFrames that takes on the value 1 if `school == \"Harvard\"` and 0 otherwise. Now, explore how each of our 12 predictors is associated with whether or not an applicant is admitted into the college to which they applied (`admitted`). Create a separate **visual** for each of our predictors to investigate their relationship with college admissions. **Suggestion:** Place these 12 visuals in a *matrix* of subplots with 3 columns and 4 rows.\n",
    "\n",
    "**NOTE:** We will be using our dummified `harvard` predictor instead of `school` throughout the remainder of this problem set.\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# college_test.head() \n",
    "\n",
    "# train_val = []\n",
    "# for k in X_train['school']:\n",
    "#     if k == 'Harvard':\n",
    "#         train_val.append(1)\n",
    "#     else:\n",
    "#         train_val.append(0)\n",
    "# X_train.loc['harvard'] = train_val \n",
    "# X_train.head() \n",
    "\n",
    "\n",
    "# test_val = []\n",
    "# for k in X_test['school']:\n",
    "#     if k == 'Harvard':\n",
    "#         test_val.append(1)\n",
    "#     else:\n",
    "        # test_val.append(0)\n",
    "# X_test['harvard'] = test_val\n",
    "# X_test.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>admitted</th>\n",
       "      <th>test_score</th>\n",
       "      <th>ap</th>\n",
       "      <th>avg_ap</th>\n",
       "      <th>sat_subjects</th>\n",
       "      <th>gpa</th>\n",
       "      <th>female</th>\n",
       "      <th>minority</th>\n",
       "      <th>international</th>\n",
       "      <th>sports</th>\n",
       "      <th>school</th>\n",
       "      <th>early_app</th>\n",
       "      <th>alumni</th>\n",
       "      <th>program</th>\n",
       "      <th>add_info</th>\n",
       "      <th>harvard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>7QE2EEAS0E</td>\n",
       "      <td>0</td>\n",
       "      <td>2160</td>\n",
       "      <td>6</td>\n",
       "      <td>4.333</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yale</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Anthropology</td>\n",
       "      <td>Have 2 jobs teaching religious school and working in archival room at local library Academic Tea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>5NSAZA57M3</td>\n",
       "      <td>0</td>\n",
       "      <td>1720</td>\n",
       "      <td>2</td>\n",
       "      <td>3.500</td>\n",
       "      <td>4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yale</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>history</td>\n",
       "      <td>president of class 3 years employed school leadership team nutrition club dance committee volunt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>BEQC4RRH81</td>\n",
       "      <td>0</td>\n",
       "      <td>2090</td>\n",
       "      <td>2</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Harvard</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Biomedical Engineering</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>7F7WPR7PVZ</td>\n",
       "      <td>0</td>\n",
       "      <td>2180</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yale</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>International Relations</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>RY2VQSAH3U</td>\n",
       "      <td>0</td>\n",
       "      <td>2360</td>\n",
       "      <td>4</td>\n",
       "      <td>5.000</td>\n",
       "      <td>3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Harvard</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Comparative Literature</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  admitted  test_score  ap  avg_ap  sat_subjects  gpa  female  \\\n",
       "1268  7QE2EEAS0E         0        2160   6   4.333             4  4.0       1   \n",
       "1511  5NSAZA57M3         0        1720   2   3.500             4  3.9       1   \n",
       "583   BEQC4RRH81         0        2090   2   4.000             3  4.0       1   \n",
       "1237  7F7WPR7PVZ         0        2180   0   0.000             2  4.0       0   \n",
       "1542  RY2VQSAH3U         0        2360   4   5.000             3  3.8       1   \n",
       "\n",
       "      minority  international  sports   school  early_app  alumni  \\\n",
       "1268         0              0       0     Yale          1       0   \n",
       "1511         1              0       0     Yale          1       0   \n",
       "583          0              0       0  Harvard          0       0   \n",
       "1237         1              1       0     Yale          0       0   \n",
       "1542         0              0       0  Harvard          0       0   \n",
       "\n",
       "                      program  \\\n",
       "1268             Anthropology   \n",
       "1511                  history   \n",
       "583    Biomedical Engineering   \n",
       "1237  International Relations   \n",
       "1542   Comparative Literature   \n",
       "\n",
       "                                                                                                 add_info  \\\n",
       "1268  Have 2 jobs teaching religious school and working in archival room at local library Academic Tea...   \n",
       "1511  president of class 3 years employed school leadership team nutrition club dance committee volunt...   \n",
       "583                                                                                                   NaN   \n",
       "1237                                                                                                  NaN   \n",
       "1542                                                                                                  NaN   \n",
       "\n",
       "      harvard  \n",
       "1268        0  \n",
       "1511        0  \n",
       "583         1  \n",
       "1237        0  \n",
       "1542        1  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college_train[\"harvard\"] = 0\n",
    "college_test[\"harvard\"] = 0\n",
    "\n",
    "mask_train = college_train['school'] == 'Harvard'\n",
    "college_train.loc[mask_train, \"harvard\"] = 1\n",
    "# mask_train_0 = college_train['school'] != 'Harvard'\n",
    "# college_train.loc[mask_train_0, \"harvard\"] = 0\n",
    "\n",
    "mask_test = college_test['school'] == 'Harvard'\n",
    "college_test.loc[mask_test, \"harvard\"] = 1\n",
    "# mask_test_0 = college_train['school'] != 'Harvard'\n",
    "# college_test.loc[mask_test_0, \"harvard\"] = 0\n",
    "\n",
    "college_train.head()\n",
    "college_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = [\"test_score\", \"ap\", \"avg_ap\", \"sat_subjects\", \"gpa\", \"female\", \"minority\", \n",
    "             \"international\",\"sports\", \"harvard\", \"early_app\", \"alumni\", \"admitted\"]\n",
    "\n",
    "college_train = college_train[pred]\n",
    "college_test = college_test[pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_score</th>\n",
       "      <th>ap</th>\n",
       "      <th>avg_ap</th>\n",
       "      <th>sat_subjects</th>\n",
       "      <th>gpa</th>\n",
       "      <th>female</th>\n",
       "      <th>minority</th>\n",
       "      <th>international</th>\n",
       "      <th>sports</th>\n",
       "      <th>harvard</th>\n",
       "      <th>early_app</th>\n",
       "      <th>alumni</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>2080</td>\n",
       "      <td>5</td>\n",
       "      <td>4.400</td>\n",
       "      <td>4</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>2190</td>\n",
       "      <td>6</td>\n",
       "      <td>3.667</td>\n",
       "      <td>3</td>\n",
       "      <td>3.97</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>2140</td>\n",
       "      <td>2</td>\n",
       "      <td>4.500</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>2120</td>\n",
       "      <td>6</td>\n",
       "      <td>3.333</td>\n",
       "      <td>3</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2400</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000</td>\n",
       "      <td>5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>2230</td>\n",
       "      <td>2</td>\n",
       "      <td>4.500</td>\n",
       "      <td>3</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>2230</td>\n",
       "      <td>5</td>\n",
       "      <td>4.800</td>\n",
       "      <td>2</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2340</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>2380</td>\n",
       "      <td>6</td>\n",
       "      <td>5.000</td>\n",
       "      <td>3</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1496 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      test_score  ap  avg_ap  sat_subjects   gpa  female  minority  \\\n",
       "584         2080   5   4.400             4  3.90       1         0   \n",
       "1817        2190   6   3.667             3  3.97       1         0   \n",
       "1308        2140   2   4.500             3  3.70       0         0   \n",
       "1336        2120   6   3.333             3  4.00       1         0   \n",
       "3           2400   5   5.000             5  4.00       1         0   \n",
       "...          ...  ..     ...           ...   ...     ...       ...   \n",
       "1114        2230   2   4.500             3  4.00       1         0   \n",
       "368         2230   5   4.800             2  4.00       0         0   \n",
       "648         2020   0   0.000             3  4.00       1         0   \n",
       "121         2340   0   0.000             2  4.00       0         0   \n",
       "1537        2380   6   5.000             3  4.00       1         0   \n",
       "\n",
       "      international  sports  harvard  early_app  alumni  \n",
       "584               0       0        1          1       0  \n",
       "1817              0       0        0          0       0  \n",
       "1308              0       0        0          0       0  \n",
       "1336              0       0        0          1       0  \n",
       "3                 0       0        1          0       0  \n",
       "...             ...     ...      ...        ...     ...  \n",
       "1114              0       0        0          0       0  \n",
       "368               0       0        1          1       0  \n",
       "648               1       0        1          0       1  \n",
       "121               0       0        1          0       0  \n",
       "1537              0       0        1          0       0  \n",
       "\n",
       "[1496 rows x 12 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_cols = [\"test_score\", \"ap\", \"avg_ap\", \"sat_subjects\", \"gpa\", \"female\", \"minority\", \n",
    "             \"international\",\"sports\", \"harvard\", \"early_app\", \"alumni\"]\n",
    "\n",
    "X_train = college_train[pred_cols]\n",
    "y_train = college_train[\"admitted\"]\n",
    "X_test = college_test[pred_cols]\n",
    "y_test = college_test[\"admitted\"]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_cols = [[0,0],[0,1],[0,2],[1,0],[1,1],[1,2],\n",
    "#             [2,0],[2,1],[2,2],[3,0],[3,1],[3,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(4, 3, figsize=(15,10))\n",
    "\n",
    "sns.scatterplot(ax=axes[0,0], data = college_train, x = pred_cols[0], y = \"admitted\")\n",
    "sns.scatterplot(ax=axes[0,1], data = college_train, x = pred_cols[1], y = \"admitted\")\n",
    "sns.scatterplot(ax=axes[0,2], data = college_train, x = pred_cols[2], y = \"admitted\")\n",
    "sns.scatterplot(ax=axes[1,0], data = college_train, x = pred_cols[3], y = \"admitted\")\n",
    "sns.scatterplot(ax=axes[1,1], data = college_train, x = pred_cols[4], y = \"admitted\")\n",
    "sns.scatterplot(ax=axes[1,2], data = college_train, x = pred_cols[5], y = \"admitted\")\n",
    "sns.scatterplot(ax=axes[2,0], data = college_train, x = pred_cols[6], y = \"admitted\")\n",
    "sns.scatterplot(ax=axes[2,1], data = college_train, x = pred_cols[7], y = \"admitted\")\n",
    "sns.scatterplot(ax=axes[2,2], data = college_train, x = pred_cols[8], y = \"admitted\")\n",
    "sns.scatterplot(ax=axes[3,0], data = college_train, x = pred_cols[9], y = \"admitted\")\n",
    "sns.scatterplot(ax=axes[3,1], data = college_train, x = pred_cols[10], y = \"admitted\")\n",
    "sns.scatterplot(ax=axes[3,2], data = college_train, x = pred_cols[11], y = \"admitted\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1.2</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q1.2 results: All test cases passed!"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**1.3** Based on the visuals above, which predictor seems to have the most potential for predicting `admitted`? Why do you think this it the best potential single predictor?\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test score, gpa, avg_ap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "    \n",
    "**Q1.4** Fit a logistic regression to predict `admitted` from `harvard` (call it `logit1_4`).  \n",
    "- Store the coefficient and intercept in `logit1_4_coef` and `logit1_4_intercept`. Interpret these values.\n",
    "- What are the estimated probabilities of getting into each school? Store these in `p_harvard` and `p_yale`. Which school is easier to get into according to this model?\n",
    "\n",
    "**IMPORTANT:** Remember, all models in this assignment should be **unregularized** unless you are specifically asked to use regularization for a particular model.\n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>harvard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1496 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      harvard\n",
       "584      True\n",
       "1817    False\n",
       "1308    False\n",
       "1336    False\n",
       "3        True\n",
       "...       ...\n",
       "1114    False\n",
       "368      True\n",
       "648      True\n",
       "121      True\n",
       "1537     True\n",
       "\n",
       "[1496 rows x 1 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_harvard = pd.DataFrame(X_train['harvard'])\n",
    "mask_X_train_harvard = pd.DataFrame(X_train['harvard'] == 1)\n",
    "mask_X_train_harvard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>harvard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1496 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      harvard\n",
       "584     False\n",
       "1817     True\n",
       "1308     True\n",
       "1336     True\n",
       "3       False\n",
       "...       ...\n",
       "1114     True\n",
       "368     False\n",
       "648     False\n",
       "121     False\n",
       "1537    False\n",
       "\n",
       "[1496 rows x 1 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_X_train_yale = pd.DataFrame(X_train['harvard'] == 0)\n",
    "mask_X_train_yale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "...\n",
    "# Fit logistic regression model without regularization\n",
    "logit1_4 = LogisticRegression(penalty='none', max_iter=10000).fit(X_train_harvard, y_train)\n",
    "# y_pred_train = logit1_4.predict(X_train)\n",
    "# Identify and report coefficients\n",
    "logit1_4_coef = float(logit1_4.coef_)\n",
    "logit1_4_intercept = float(logit1_4.intercept_)\n",
    "# Calculate and report probabilities\n",
    "p_harvard = float(np.mean(logit1_4.predict_proba(mask_X_train_harvard)[:,1]))\n",
    "p_yale = float(np.mean(logit1_4.predict_proba(mask_X_train_yale)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient for the 'logit1_4' model's only predictor 'harvard' is 0.1532 and the intercept is -1.1137\n",
      "\n",
      "Estimated probability of acceptance for Harvard: 0.2627\n",
      "Estimated probability of acceptance for Yale: 0.2613\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"The coefficient for the 'logit1_4' model's only predictor 'harvard' \"\n",
    "    \"is {:.4f} and the intercept is {:.4f}\\n\".format(\n",
    "        logit1_4_coef, logit1_4_intercept\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Estimated probability of acceptance for Harvard: {:.4f}\"\n",
    "    .format(p_harvard)\n",
    ")\n",
    "print(\n",
    "    \"Estimated probability of acceptance for Yale: {:.4f}\"\n",
    "    .format(p_yale)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>q1.4</pre> results:</strong></p><p><strong><pre style='display: inline;'>q1.4 - 1</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q1.4 - 2</pre> result:</strong></p><pre>    Trying:\n",
       "        assert np.isclose(p_harvard, 0.2768, atol=0.0001), \"Incorrect value for p_harvard\"\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 2, in q1.4 1\n",
       "    Failed example:\n",
       "        assert np.isclose(p_harvard, 0.2768, atol=0.0001), \"Incorrect value for p_harvard\"\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/Users/karenkuo/opt/anaconda3/lib/python3.9/doctest.py\", line 1334, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q1.4 1[0]>\", line 1, in <module>\n",
       "            assert np.isclose(p_harvard, 0.2768, atol=0.0001), \"Incorrect value for p_harvard\"\n",
       "        AssertionError: Incorrect value for p_harvard\n",
       "    Trying:\n",
       "        assert np.isclose(p_yale, 0.2472, atol=0.0001), \"Incorrect value for p_yale\"\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 3, in q1.4 1\n",
       "    Failed example:\n",
       "        assert np.isclose(p_yale, 0.2472, atol=0.0001), \"Incorrect value for p_yale\"\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/Users/karenkuo/opt/anaconda3/lib/python3.9/doctest.py\", line 1334, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q1.4 1[1]>\", line 1, in <module>\n",
       "            assert np.isclose(p_yale, 0.2472, atol=0.0001), \"Incorrect value for p_yale\"\n",
       "        AssertionError: Incorrect value for p_yale\n",
       "</pre>"
      ],
      "text/plain": [
       "q1.4 results:\n",
       "    q1.4 - 1 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q1.4 - 2 result:\n",
       "        Trying:\n",
       "            assert np.isclose(p_harvard, 0.2768, atol=0.0001), \"Incorrect value for p_harvard\"\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 2, in q1.4 1\n",
       "        Failed example:\n",
       "            assert np.isclose(p_harvard, 0.2768, atol=0.0001), \"Incorrect value for p_harvard\"\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/Users/karenkuo/opt/anaconda3/lib/python3.9/doctest.py\", line 1334, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q1.4 1[0]>\", line 1, in <module>\n",
       "                assert np.isclose(p_harvard, 0.2768, atol=0.0001), \"Incorrect value for p_harvard\"\n",
       "            AssertionError: Incorrect value for p_harvard\n",
       "        Trying:\n",
       "            assert np.isclose(p_yale, 0.2472, atol=0.0001), \"Incorrect value for p_yale\"\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 3, in q1.4 1\n",
       "        Failed example:\n",
       "            assert np.isclose(p_yale, 0.2472, atol=0.0001), \"Incorrect value for p_yale\"\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/Users/karenkuo/opt/anaconda3/lib/python3.9/doctest.py\", line 1334, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q1.4 1[1]>\", line 1, in <module>\n",
       "                assert np.isclose(p_yale, 0.2472, atol=0.0001), \"Incorrect value for p_yale\"\n",
       "            AssertionError: Incorrect value for p_yale"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1.4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**Q1.5** Create and display a [contingency table](https://en.wikipedia.org/wiki/Contingency_table) between `admitted` and `harvard`.  Use this table to calculate and confirm the coefficient estimates in the `logit1_4` model (both the intercept and slope). Show this calculation using $\\LaTeX$ in a markdown cell.\n",
    "    \n",
    "**Hint:** The Pandas [crosstab](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.crosstab.html) method may be helpful here.\n",
    "\n",
    "</div>\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>harvard</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admitted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>176</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "harvard     0    1\n",
       "admitted          \n",
       "0         536  567\n",
       "1         176  217"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(college_train['admitted'],college_train['harvard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    784\n",
       "0    712\n",
       "Name: harvard, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college_train['harvard'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1103\n",
       "1     393\n",
       "Name: admitted, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college_train['admitted'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Harvard:\n",
    "P(Y=1) = 217/784 ≈ 0.277\n",
    "P(Y=0) = 567/784 ≈ 0.723\n",
    "\n",
    "\n",
    "Yale:\n",
    "P(Y=1) = 176/712 ≈ 0.247\n",
    "P(Y=0) = 536/712 ≈ 0.752\n",
    "\n",
    "β0 +  β1x1 = ln(P(Y=1)/P(Y=0)) \n",
    "β0 +  β1x1 = ln(0.277/0.723) ≈ 0.382\n",
    "\n",
    "\n",
    "\n",
    "β0 +  β1x1 = ln(P(Y=1)/P(Y=0)) \n",
    "β0 +  β1x1 = ln(0.247/0.752) ≈ 0.328\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**Q1.6** Compare the estimated probabilities of being admitted into the schools to the overall acceptance rate (as seen [here](https://www.ivycoach.com/2023-ivy-league-admissions-statistics/)).  Why may what you've observed in this comparison be the case?\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is not complete, it is only showing values from students volunteer to share their results. The actual results are way hgiher than the dataset. For instance, the total application received should be 43,330. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part2\"></a>\n",
    "\n",
    "## <div class='exercise'>Question 2: Interpretable modeling [18 pts]</div>\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**Q2.1** \n",
    "    \n",
    "- Fit a logistic regression model to predict `admitted` from `test_score` alone. Call it `logit2_1`.\n",
    "- Store the learned parameters in `logit2_1_beta0` and `logit2_1_beta1`. \n",
    "- Store the train and test classification accuracies for this model in `acc_train_logit2_1` and `acc_test_logit2_1`.\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "logit2_1 = LogisticRegression(penalty='none', max_iter=10000).fit(pd.DataFrame(X_train['test_score']), y_train)\n",
    "\n",
    "logit2_1_intercept = float(logit2_1.intercept_)\n",
    "logit2_1_coef_test = float(logit2_1.coef_)\n",
    "\n",
    "acc_train_logit2_1 = float(logit2_1.score(pd.DataFrame(X_train['test_score']), y_train))\n",
    "acc_test_logit2_1 = float(logit2_1.score(pd.DataFrame(X_test['test_score']), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The intercept and coefficient for the 'logit2_1' model are:\n",
      "\tintercept           -9.4136\n",
      "\ttest                0.0038\n",
      "\n",
      "The classification accuracies for 'logit2_1' are:\n",
      "\n",
      "\tTrain\t0.7373\n",
      "\tTEST\t0.7013\n"
     ]
    }
   ],
   "source": [
    "print(\"The intercept and coefficient for the 'logit2_1' model are:\")\n",
    "\n",
    "print(\"\\t{:<20}{:.4f}\".format('intercept', logit2_1_intercept))\n",
    "print(\"\\t{:<20}{:.4f}\".format('test', logit2_1_coef_test))\n",
    "\n",
    "print(\n",
    "    \"\\nThe classification accuracies for 'logit2_1' are:\"\n",
    "    \"\\n\\n\\tTrain\\t{:.4f}\\n\\tTEST\\t{:.4f}\".format(\n",
    "        acc_train_logit2_1, acc_test_logit2_1\n",
    "    )\n",
    ")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2.1</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2.1 results: All test cases passed!"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**Q2.2**\n",
    "    \n",
    "- What is the estimated probability of an applicant being admitted with an *average* `test` score of 2250? Store this in `prop_test_2250`.\n",
    "- What about if they had a perfect test score of 2400? Store this in `prop_test_2400`.\n",
    "- What test score would be needed to have a 50-50 chance (i.e. 0.5 probability) of being admitted? Store this in `test_50_50`.\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict_proba() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [177]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# your code here\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m prob_test_2250 \u001b[38;5;241m=\u001b[39m \u001b[43mlogit2_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2250\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m prob_test_2400 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m      5\u001b[0m test_50_50 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: predict_proba() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "prob_test_2250 = logit2_1.predict_proba(2250,1)\n",
    "prob_test_2400 = ...\n",
    "\n",
    "test_50_50 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "print(\n",
    "    \"The estimated chances of an applicant being admitted with \"\n",
    "    \"the following two 'test' scores:\\n\\n\\tscore\\tprobabilities\"\n",
    "    \"\\n\\t2250\\t{:.4f}\\n\\t2400\\t{:.4f}\\n\"\n",
    "    .format(prob_test_2250, prob_test_2400)\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"The test score required to have a 50-50 chance of being \"\n",
    "    \"admitted is approximately:\\n\\n\\t{:.2f}\"\n",
    "    .format(test_50_50)\n",
    ")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**Q2.3** Fit a logistic regression model to predict `admitted` from `test_score` and `avg_ap` (call it `logit2_3`).  Print out the coefficient estimates along with the classification accuracies for this model (on both train and test data).\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "...\n",
    "logit2_3 = ...\n",
    "\n",
    "logit2_3_coef_test = ...\n",
    "logit2_3_coef_avg_ap = ...\n",
    "logit2_3_intercept = ...\n",
    "\n",
    "acc_train_logit2_3 = ...\n",
    "acc_test_logit2_3 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the parameters of logit2_3\n",
    "print(\"The intercept and coefficients for the 'logit2_3' model are:\")\n",
    "print(\"\\t{:<20}{:.4f}\".format('intercept', logit2_3_intercept))\n",
    "print(\"\\t{:<20}{:.4f}\".format('test', logit2_3_coef_test))\n",
    "print(\"\\t{:<20}{:.4f}\".format('avg_ap', logit2_3_coef_avg_ap))\n",
    "\n",
    "print(\n",
    "    \"\\nThe classification accuracies for 'logit2_3' are:\\n\\n\\tTrain\\t{:.4f}\\n\\tTEST\\t{:.4f}\"\n",
    "    .format(acc_train_logit2_3, acc_test_logit2_3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**Q2.4** Interpret the coefficient estimates for both predictors in `logit2_3` and compare the coefficient estimate for `test_score` to the one from `logit2_1`.  Why has this estimate changed?\n",
    "\n",
    "You should inspect the relationship between `test_score` and `avg_ap` to help get a better sense for what might be happening here.\n",
    "\n",
    "</div>\n",
    "\n",
    "_Points:_ 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the parameters of the last 2 models\n",
    "print(\"The intercept and coefficient for the 'logit2_1' model are:\")\n",
    "\n",
    "print(\"\\t{:<20}{:.4f}\".format('intercept', logit2_1_intercept))\n",
    "print(\"\\t{:<20}{:.4f}\".format('test_score', logit2_1_coef_test))\n",
    "\n",
    "print(\"The intercept and coefficients for the 'logit2_3' model are:\")\n",
    "print(\"\\t{:<20}{:.4f}\".format('intercept', logit2_3_intercept))\n",
    "print(\"\\t{:<20}{:.4f}\".format('test_score', logit2_3_coef_test))\n",
    "print(\"\\t{:<20}{:.4f}\".format('avg_ap', logit2_3_coef_avg_ap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**Q2.5** Interpret and compare the classification accuracies for the two models, `logit2_1` and `logit2_3`.  Explain why these accuracies are the same or different, and what about the data makes these accuracies so similar or different.\n",
    "\n",
    "</div>\n",
    "\n",
    "_Points:_ 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display accuracies of last 2 models\n",
    "print(\n",
    "    \"\\nThe classification accuracies for 'logit2_1' are:\\n\\n\\tTrain\\t{:.4f}\\n\\tTEST\\t{:.4f}\"\n",
    "    .format(acc_train_logit2_1, acc_test_logit2_1)\n",
    ")\n",
    "print(\n",
    "    \"\\nThe classification accuracies for 'logit2_3' are:\\n\\n\\tTrain\\t{:.4f}\\n\\tTEST\\t{:.4f}\"\n",
    "    .format(acc_train_logit2_3, acc_test_logit2_3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part3\"></a>\n",
    "\n",
    "## <div class='exercise'>Question 3: Harvard and Yale? [30 pts]</div>\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**Q3.1**\n",
    "- Fit a logistic regression model (call it `logit3_1`) to predict `admitted` from 7 predictors: `[\"harvard\", \"test_score\", \"ap\", \"avg_ap\", \"gpa\", \"female\", \"minority\"]`.\n",
    "- Store the train and test accuracies in `acc_train_logit3_1` and `acc_test_logit3_1`.\n",
    "- Use the code provided to output the coefficient estimates. Interpret the coefficients for the binary predictors in this model.\n",
    "\n",
    "**HINT:** If you have convergence warnings, increasing the maximum number of iterations will likely solve this issue.\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print statements below assume predictors used in this order\n",
    "logit3_1_predictors = [\"harvard\", \"test_score\", \"ap\", \"avg_ap\", \"gpa\", \"female\", \"minority\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "...\n",
    "logit3_1 = ...\n",
    "acc_train_logit3_1 = ...\n",
    "acc_test_logit3_1 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grab model's intercept and coefs regardless of their shape\n",
    "# (which depends on how x and y were shaped)\n",
    "logit3_1_intercept = np.array(logit3_1.intercept_).flatten()[0]\n",
    "logit3_1_coefs = logit3_1.coef_.flatten()\n",
    "\n",
    "print(\n",
    "    \"The intercept and coefficients for the 'logit3_1' model are:\"\n",
    "    \"\\n\\n\\t{:<20}{:.4f}\".format(\n",
    "        \"intercept\", logit3_1_intercept\n",
    "    )\n",
    ")\n",
    "for predictor, coef in zip(logit3_1_predictors, logit3_1_coefs):\n",
    "    print(\"\\t{:<20}{:.4f}\".format(predictor, coef))\n",
    "\n",
    "print(\n",
    "    \"\\nThe classification accuracies for 'logit3_1' are:\"\n",
    "    \"\\n\\n\\tTrain\\t{:.4f}\\n\\tTEST\\t{:.4f}\"\n",
    "    .format(acc_train_logit3_1, acc_test_logit3_1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**Q3.2** Fit a logistic regression model (call it `logit3_2`) to predict `admitted` from 3 predictors: `[\"harvard\", \"test_score\", \"ap\"]` along with the 2 interaction terms: `harvard` with `test_score` and `harvard` with `ap`. Name the columns for these interaction terms `harvard_test_score` and `harvard_ap`.\n",
    "\n",
    "</div>\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print statement below assumes this order of predictors\n",
    "logit3_2_predictors = [\"harvard\", \"test_score\", \"ap\", \"harvard_test_score\", \"harvard_ap\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "...\n",
    "logit3_2 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display results\n",
    "logit3_2_intercept = np.array(logit3_2.intercept_).flatten()[0]\n",
    "logit3_2_coefs = logit3_2.coef_.flatten()\n",
    "\n",
    "print(\n",
    "    \"The intercept and coefficients for the 'logit3_2' model are:\"\n",
    "    \"\\n\\n\\t{:<20}{:.4f}\".format(\n",
    "        \"intercept\", logit3_2_intercept\n",
    "    )\n",
    ")\n",
    "\n",
    "for predictor, coef in zip(logit3_2_predictors, logit3_2_coefs):\n",
    "    print(\"\\t{:<20}{:.4f}\".format(predictor, coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**Q3.3** Simplify and write out mathematically the above model from Question 3.2 for 2 applicants: (1) someone who is applying to Harvard and for (2) someone who is applying to Yale (keep `test_score` and `ap` as the unknown $X$s).  The basic framework given to you below may be helpful:\n",
    "\n",
    "$$ \\ln \\left( \\frac{P(Y=1)}{1-P(Y=1)} \\right) = \\beta_0 + \\beta_1 X_1 + \\dots + \\beta_p X_p $$\n",
    "    \n",
    "**NOTE:** All of your mathematical statements should be written out in your markdown cells using $\\LaTeX$. Show all your steps, not just the final result.\n",
    "\n",
    "</div>\n",
    "\n",
    "_Points:_ 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**Q3.4** Determine two classification boundaries mathematically for the model in the previous part (using the estimated coefficients): What range of values of `test_score` as a function of `ap` would an applicant be predicted to have a better than 50% chance (i.e. 0.5 probability) of being admitted into the college they applied to? \n",
    "\n",
    "Use the function for Harvard to answer the following question: if a student scored a perfect 2400 on `test_score`, what is the range of AP tests they should take in order to have a better than 50% chance of being admitted into Harvard?\n",
    "\n",
    "Again, you should show your work in $\\LaTeX$.\n",
    "</div>\n",
    "\n",
    "_Points:_ 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**Q3.5** Create two separate scatterplots (one for Harvard applicants and one for Yale applicants) with the predictor `test_score` on the y-axis and `ap` on the x-axis where `admitted` is color-coded and the marker denotes train vs. test data.  Then add the appropriate classification boundary from the previous part.  Compare these two plots (including both the location of the boundaries and where the points lie around these boundaries).\n",
    "\n",
    "**NOTE:** As always, please be certain (a) your plot is titled, (b) everything is clearly labeled, and (c) the plot itself is formatted in a manner that makes it easy to read and interpret. It will likely take some careful work here to generate plots with data points that are clear and easy to see. You might try 'dithering' the points with a random offset so they are not all on top of one another.\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**Q3.6** Fit a logistic regression model (call it `logit3_6`) to predict `admitted` from 4 predictors: `[\"harvard\", \"test_score\", \"female\", \"minority\"]` along with 2 interaction terms: `harvard` with `female` and `harvard` with `minority`. \n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided code assumes this order of predictors\n",
    "logit3_6_predictors = [\"harvard\",\n",
    "                       \"test_score\",\n",
    "                       \"female\",\n",
    "                       \"minority\",\n",
    "                       \"harvard_female\",\n",
    "                       \"harvard_minority\"\n",
    "                      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "...\n",
    "logit3_6 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3.6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**Q3.7** Interpret the coefficients associated with `female` and `minority` (the two main effects AND the two interaction terms).\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "logit3_6_intercept = np.array(logit3_6.intercept_).flatten()[0]\n",
    "logit3_6_coefs = logit3_6.coef_.flatten()\n",
    "\n",
    "print(\n",
    "    \"The intercept and coefficients for the 'logit3_6' model are:\"\n",
    "    \"\\n\\n\\t{:<20}{:.4f}\".format(\n",
    "        \"intercept\", logit3_6_intercept\n",
    "    )\n",
    ")\n",
    "\n",
    "for predictor, coef in zip(logit3_6_predictors, logit3_6_coefs):\n",
    "    print(\"\\t{:<20}{:.4f}\".format(predictor, coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**Q3.8** Based on this sample, how does it appear that Harvard and Yale compare in admitting women and minorities?  Why would it be wrong to take this interpretation as truth?\n",
    "\n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part4\"></a>\n",
    "\n",
    "## <div class='exercise'>Question 4: Building predictive models for admitted [24 pts]</div>\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**Q4.1** You were instructed to NOT scale predictors in the prior sections above. The primary reason for this was to focus instead on the interpretability of our logistic regression coefficients. However, as we're sure you noticed, the numeric scale among our different predictors varies greatly (i.e. `test_score` values are in the 1,000's while others are much, much smaller). In practice, we might want to put our predictors all on a similar scale, particularly for regularized regression and/or distance-based algorithms such as $k$-NN classification. **(1)** Please explain why scaling under these circumstances might be important. Then, **(2)** actually apply standardized scaling to all of the **non-binary** predictors in our original set of 12 predictors. **For the sake of consistency, fit your scaler on just the training data. Then use it to transform both train and test.**\n",
    "\n",
    "**IMPORTANT:** These scaled predictors should be used instead of the original unscaled versions of the predictors for the remainder of this problem set. Tests from this point on assume that `X_train` and `X_test` have been standardized with the approach outlined above. \n",
    "\n",
    "</div>\n",
    "\n",
    "_Points:_ 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview summary stats after standardizing\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**Q4.2** Fit a well-tuned $k$-NN classification model with main effects of all 12 predictors in it (call it `knn_model`).  Use `ks = [1, 3, 5, 9, 15, 21, 51, 71, 101, 131, 171, 201]` and 10-fold cross-validation with classification accuracy as the scoring metric. Plot, on a single set of axes, your resulting cross-validation mean training and mean validation scores at each value $k$. Then, store your chosen $k$ in `best_k` and the classification accuracy on train and test for your final fitted model as `knn_train_acc` and `knn_test_acc`.\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(121) # Do not delete or modify this line of code\n",
    "\n",
    "# your code here\n",
    "...\n",
    "best_k = ...\n",
    "...\n",
    "knn_train_acc = ...\n",
    "knn_test_acc = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot cross-validation results\n",
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"The classification accuracies for 'knn_model' where k={} \"\n",
    "    \"are:\\n\\n\\tTrain\\t{:.4f}\\n\\tTEST\\t{:.4f}\"\n",
    "    .format(\n",
    "        best_k, knn_train_acc, knn_test_acc\n",
    "    )\n",
    ")\n",
    "\n",
    "# create dict for storing test scores for each Q4 model\n",
    "q4_test_scores = {\"knn_model\": knn_test_acc}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**Q4.3** Fit the full logistic regression model (without penalty) with main effects of all 12 predictors in it (call it `logit_full`). Store the classification accuracy on train and test for this model in `logit_full_train_acc` and `logit_full_test_acc`.\n",
    "\n",
    "**HINT:** If you have convergence warnings, increasing the maximum number of iterations will likely solve this issue.\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code that prints your results assumes\n",
    "# predictors were given to the model in this order\n",
    "predictor_list = [\n",
    "    \"test_score\", \"ap\", \"avg_ap\", \"sat_subjects\",\n",
    "    \"gpa\", \"female\", \"minority\", \"international\",\n",
    "    \"sports\", \"harvard\", \"early_app\", \"alumni\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "logit_full = ...\n",
    "\n",
    "logit_full_train_acc = ...\n",
    "logit_full_test_acc = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display your results\n",
    "print(\n",
    "    \"The intercept and coefficients for the 'logit_full' model are:\"\n",
    "    \"\\n\\n\\t{:<20}{:.4f}\".format(\n",
    "        \"intercept\", np.array(logit_full.intercept_).flatten()[0]\n",
    "    )\n",
    ")\n",
    "\n",
    "for predictor, coef in zip(predictor_list, logit_full.coef_.flatten()):\n",
    "    print(\"\\t{:<20}{:.4f}\".format(predictor, coef))\n",
    "\n",
    "print(\n",
    "    \"\\nThe classification accuracies for 'logit_full' are:\"\n",
    "    \"\\n\\n\\tTrain\\t{:.4f}\\n\\tTEST\\t{:.4f}\"\n",
    "    .format(logit_full_train_acc, logit_full_test_acc)\n",
    ")\n",
    "\n",
    "# store test score to dict for later use\n",
    "q4_test_scores[\"logit_full\"] = logit_full_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**Q4.4** Fit a well-tuned Lasso-like logistic regression model from all 12 predictors in it (call it `logit_lasso`). Use `Cs = [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4]` and 10-fold cross-validation with classification accuracy as the scoring metric. Store the classification accuracy on train and test for this model in `logit_lasso_train_acc` and `logit_lasso_test_acc`.\n",
    "\n",
    "</div>\n",
    "\n",
    "_Points:_ 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "...\n",
    "logit_lasso = ...\n",
    "\n",
    "logit_lasso_train_acc = ...\n",
    "logit_lasso_test_acc = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display your results\n",
    "print(\n",
    "    \"The intercept and coefficients for the 'logit_lasso' model are:\"\n",
    "    \"\\n\\n\\t{:<20}{:.4f}\".format(\n",
    "        \"intercept\", np.array(logit_lasso.intercept_).flatten()[0]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Again, this code assumes predictors were given to the model\n",
    "# in the order defined in `predictor_list`\n",
    "for predictor, coef in zip(predictor_list, logit_lasso.coef_.flatten()):\n",
    "    print(\"\\t{:<20}{:.4f}\".format(predictor, coef))\n",
    "\n",
    "print(\n",
    "    \"\\nThe classification accuracies for 'logit_lasso' are:\"\n",
    "    \"\\n\\n\\tTrain\\t{:.4f}\\n\\tTEST\\t{:.4f}\"\n",
    "    .format(logit_lasso_train_acc, logit_lasso_test_acc)\n",
    ")\n",
    "\n",
    "# store test score to dict for later use\n",
    "q4_test_scores[\"logit_lasso\"] = logit_lasso_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4.4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**4.5** Which predictors were deemed important in `logit_lasso`?  Which were deemed unimportant? Please remember that, as a general practice, zero-value Lasso coefficients (i.e. $\\beta_i=0$) are considered \"unimportant\". Store your results in `predictors_important` and `predictors_not_important`.\n",
    " \n",
    "</div>\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "...\n",
    "predictors_important = ...\n",
    "predictors_not_important = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display results\n",
    "print(\n",
    "    \"The following predictors were deemed important by \"\n",
    "    \"'logit_lasso' (i.e. coef != 0):\\n\\n\\t{}\\n\\n\\n\"\n",
    "    \"While, the remaining were deemed unimportant (i.e. \"\n",
    "    \"coef == 0):\\n\\n\\t{}\"\n",
    "    .format(\n",
    "        predictors_important,\n",
    "        predictors_not_important,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**Q4.6** Fit a well-tuned Lasso-like logistic regression model with all important predictors from `logit_lasso` and all the unique 2-way interactions between them (call it `lasso_interact`).  Again use `Cs = [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4]` and 10-fold cross-validation with classification accuracy as the scoring metric. Record the accuracy on train and test for this model in `lasso_interact_train_acc` and `lasso_interact_test_acc`.\n",
    "\n",
    "</div>\n",
    "\n",
    "_Points:_ 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "...\n",
    "lasso_interact = ...\n",
    "lasso_interact_train_acc = ...\n",
    "lasso_interact_test_acc = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    \"\\nThe classification accuracies for 'logit_lasso_interact' are:\"\n",
    "    \"\\n\\n\\tTrain\\t{:.4f}\\n\\tTEST\\t{:.4f}\\n\"\n",
    "    .format(lasso_interact_train_acc, lasso_interact_test_acc)\n",
    ")\n",
    "\n",
    "# store test score to dict for later use\n",
    "q4_test_scores[\"lasso_interact\"] = lasso_interact_test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**Q4.7** How many of the predictors in our `logit_lasso_interact` model were deemed important and unimportant? Store these numbers in `num_important_coefs` and `num_unimportant_coefs`. \n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "...\n",
    "num_important_coefs = ...\n",
    "num_unimportant_coefs = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Of the {} predictors used in our 'logit_lasso_interact' model:\"\n",
    "    \"\\n\\n\\t{} predictors were deemed 'important' by our model\"\n",
    "    \"\\n\\t{} predictors were deemed 'unimportant' with 0-valued \"\n",
    "    \"coefficients\".format(\n",
    "        num_important_coefs + num_unimportant_coefs,\n",
    "        num_important_coefs,\n",
    "        num_unimportant_coefs\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part5\"></a>\n",
    "\n",
    "## <div class='exercise'>Question 5: Evaluating results [12 pts]</div>\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**Q5.1** Which of the 4 models in Question 4 performs the best based on classification accuracy?  Which performs the worst? Based on these accuracies, how do these models perform compared to your baseline \"naive\" model back in Question 1.1? What does this comparison to the \"naive\" model tell us?\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "print(\"The TEST accuracies for the 4 models in Q4 are:\\n\")\n",
    "for key, value in q4_test_scores.items():\n",
    "    print(\"\\t{:<25}{:.4f}\".format(key, value))\n",
    "print(\n",
    "    \"\\nThe TEST accuracy for our original baseline \\\"naive\\\" \"\n",
    "    \"model was {:.4f}\".format(naive_test_acc)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**Q5.2** Draw the four ROC curves on the same set of axes using the test data.  How do these ROC curves compare?  Do the ROC curves support that the best model identified in Question 5.1 is better than the worst model identified in 5.1?  How do you know?\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 4.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**5.3** Calculate the AUC for all 4 models and store these in `auc_list`. **The order of AUCs in the list should match the order of the model as they appear in `q4_test_scores`.**\n",
    "    \n",
    "Do the rankings of these 4 models based on AUC match those for classification accuracy?  Why do you think this is the case?\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "# calculate each model's AUC using its ROC fpr and tpr\n",
    "auc_list = ...\n",
    "    \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    \"The TEST accuracies vs. AUC scores for the 4 models in Q4 are:\"\n",
    "    \"\\n\\n\\t\\t\\t\\tAccuracy\\tAUC\"\n",
    ")\n",
    "for (key, value), auc_value in zip(q4_test_scores.items(), auc_list):\n",
    "    print(\"\\t{:<24}{:.4f}\\t\\t{:.4f}\".format(key, value, auc_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0a790850-87c6-4f46-b89e-048a2295c92b",
    "colab_type": "text",
    "id": "IGFtXJmQap2q"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**Q5.4** If you were to use one of these 4 models to present as a prediction model for the website [collegedata.com](https://www.collegedata.com/), which would you use and why?  What may be the biggest issue if this was a publicly available tool for college applicants to use to determine their chances of getting into Harvard and/or Yale?\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**This concludes HW5. Thank you!**\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1.1": {
     "name": "q1.1",
     "points": 2.5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> to_test =  [prop_admitted_train, naive_train_acc, naive_test_acc]\n>>> for var in to_test:\n...     assert isinstance(prop_admitted_train, (float, np.float_)),\\\n...     \"all requested variables should be a floats\"\n...     assert var >= 0 and var <= 1,\\\n...     \"all requested variables should be in the range [0,1]\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.2": {
     "name": "q1.2",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'harvard' in X_train.columns, \"'harvard' should be a new column in your train dataframe\"\n>>> assert 'harvard' in X_test.columns, \"'harvard' should be a new column in your test dataframe\"\n>>> assert set(X_train.harvard.unique()) == {0,1},\\\n...     \"'harvard' predictor in train should be zeros and ones\"\n>>> assert set(X_test.harvard.unique()) == {0,1},\\\n...     \"'harvard' predictor in test should be zeros and ones\"\n",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.4": {
     "name": "q1.4",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert type(logit1_4) == type(LogisticRegression()),\\\n...     \"logit1_4 should be am sklearn LogisticRegression object\"\n>>> assert p_harvard > 0.24 and p_harvard < 0.28, \"p_harvard should be between 0.24 and 0.28\"\n>>> assert p_yale > 0.24 and p_yale < 0.28, \"p_yale should be between 0.24 and 0.28\"\n",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> # HIDDEN\n>>> assert np.isclose(p_harvard, 0.2768, atol=0.0001), \"Incorrect value for p_harvard\"\n>>> assert np.isclose(p_yale, 0.2472, atol=0.0001), \"Incorrect value for p_yale\"\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.1": {
     "name": "q2.1",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert logit2_1_intercept >= -10 and logit2_1_intercept <= 10,\\\n...     \"logit2_1_beta0 should be a float between -10 and 10\"\n>>> assert logit2_1_coef_test >= -1 and logit2_1_coef_test <= 1,\\\n...     \"logit2_1_beta1 should be a float between -1 and 1\"\n>>> assert acc_train_logit2_1 > 0.7 and acc_train_logit2_1 < 0.8,\\\n...     \"acc_train_logit2_1 should be a float between 0.7 and 0.8\"\n>>> assert acc_test_logit2_1 > 0.7 and acc_train_logit2_1 < 0.8,\\\n...     \"acc_train_logit2_1 should be a float between 0.7 and 0.8\"\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.2": {
     "name": "q2.2",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert prob_test_2250 >= 0.25 and prob_test_2250 <= 0.5,\\\n...     \"prob_test_2250 should be a float between 0.25 and 0.5\"\n>>> assert prob_test_2400 >= 0.25 and prob_test_2250 <= 0.5,\\\n...     \"prob_test_2400 should be a float between 0.25 and 0.5\"\n>>> assert test_50_50 > 2200,\\\n...     \"test_50_50 should be a float greater than 2200\"\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.3": {
     "name": "q2.3",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert logit2_3_intercept >= -1 and logit2_3_intercept <= 1,\\\n...     \"logit2_3_intercept should be a float between -10 and 10\"\n>>> assert logit2_3_coef_test >= -1 and logit2_3_coef_test <= 1,\\\n...     \"logit2_3_coef_test should be a float between -1 and 1\"\n>>> assert logit2_3_coef_avg_ap >= -1 and logit2_3_coef_avg_ap <= 1,\\\n...     \"logit2_3_coef_avg_ap should be a float between -1 and 1\"\n>>> assert acc_train_logit2_3 > 0.7 and acc_train_logit2_3 < 0.8,\\\n...     \"acc_train_logit2_3 should be a float between 0.7 and 0.8\"\n>>> assert acc_test_logit2_3 > 0.7 and acc_train_logit2_3 < 0.8,\\\n...     \"acc_train_logit2_3 should be a float between 0.7 and 0.8\"\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.1": {
     "name": "q3.1",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert acc_train_logit3_1 > 0.68 and acc_train_logit3_1 < 0.78,\\\n...     \"acc_train_logit3_1 should be a float between 0.68 and 0.78\"\n>>> assert acc_test_logit3_1 > 0.68 and acc_train_logit3_1 < 0.78,\\\n...     \"acc_train_logit3_1 should be a float between 0.68 and 0.78\"\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.2": {
     "name": "q3.2",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert len(logit3_2_coefs) == 5,\\\n...     \"logit3_2 should have 5 coefficients (not including the intercept)\"\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.6": {
     "name": "q3.6",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert len(logit3_6.coef_.flatten()) == 6,\\\n...     \"logit3_6 should have 6 coefficients (not including the intercept)\"\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4.1": {
     "name": "q4.1",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert np.isclose(X_train[non_binary_predictors].values.mean(), 0),\\\n...     \"Non-binary predictors in train should now have mean 0\"\n>>> assert np.isclose(X_test[non_binary_predictors].values.mean(), 0, atol=0.1),\\\n...     \"Non-binary predictors in test should now have mean near 0\"\n>>> assert np.isclose(X_train[non_binary_predictors].values.std(), 1),\\\n...     \"Non-binary predictors in train should now have std 1\"\n>>> assert np.isclose(X_test[non_binary_predictors].values.std(), 1, atol=0.1),\\\n...     \"Non-binary predictors in test should now have std near 1\"\n>>> assert set(X_train['harvard'].unique()) == {0,1},\\\n...     \"You should not scale the binary predictors.\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4.3": {
     "name": "q4.3",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert logit_full_train_acc > 0.68 and logit_full_train_acc < 0.78,\\\n...     \"logit_full_train_acc should be a float between 0.68 and 0.78\"\n>>> assert logit_full_test_acc > 0.68 and logit_full_test_acc < 0.78,\\\n...     \"logit_full_test_acc should be a float between 0.68 and 0.78\"\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4.4": {
     "name": "q4.4",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert logit_lasso_train_acc > 0.68 and logit_lasso_train_acc < 0.78,\\\n...     \"logit_lasso_train_acc should be a float between 0.68 and 0.78\"\n>>> assert logit_lasso_test_acc > 0.68 and logit_lasso_test_acc < 0.78,\\\n...     \"logit_lasso_test_acc should be a float between 0.68 and 0.78\"\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4.5": {
     "name": "q4.5",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert len(predictors_important) >= 6,\\\n...     \"You should have more important predictors\"\n>>> assert len(predictors_not_important) <= 6,\\\n...     \"You should have fewer non-important predictors\"\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4.7": {
     "name": "q4.7",
     "points": 2,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5.3": {
     "name": "q5.3",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert len(auc_list) == 4,\\\n...     \"You should have 4 entries in auc_list\"\n",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
