{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"cs109a_hw7.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109A Introduction to Data Science\n",
    "\n",
    "## Homework 7: Fairness and Bias\n",
    "\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2022**<br/>\n",
    "**Instructors**: Pavlos Protopapas and Natesh Pillai\n",
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\n",
    "    \"https://raw.githubusercontent.com/Harvard-IACS/2021-CS109A/master/\"\n",
    "    \"themes/static/css/cs109.css\"\n",
    ").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(112358)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, roc_curve, roc_auc_score\n",
    ")                           \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### Instructions\n",
    "- To submit your assignment follow the instructions given in Canvas.\n",
    "- Plots should be legible and interpretable without having to refer to the code that generated them, including labels for the $x$- and $y$-axes as well as a descriptive title and/or legend when appropriate.\n",
    "- When asked to interpret a visualization, do not simply describe it (e.g., \"the curve has a steep slope up\"), but instead explain what you think the plot *means*.\n",
    "- The use of 'hard-coded' values to try and pass tests rather than solving problems programmatically will not receive credit.\n",
    "- The use of *extremely* inefficient or error-prone code (e.g., copy-pasting nearly identical commands rather than looping) may result in only partial credit.\n",
    "- We have tried to include all the libraries you may need to do the assignment in the imports cell provided below. Please get course staff approval before importing any additional 3rd party libraries.\n",
    "- Enable scrolling output on cells with very long output.\n",
    "- Feel free to add additional code or markdown cells as needed.\n",
    "- Ensure your code runs top to bottom without error and passes all tests by restarting the kernel and running all cells. This is how the notebook will be evaluated (note that this can take a few minutes). \n",
    "- **You should do a \"Restart Kernel and Run All Cells\" before submitting to ensure (1) your notebook actually runs and (2) all output is visible**\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"contents\"></a>\n",
    "\n",
    "## Notebook contents\n",
    "\n",
    "- [**Required reading and data description**](#intro)\n",
    "\n",
    "\n",
    "- [**Question 1: Data exploration [26 pts]**](#part1)\n",
    "\n",
    "\n",
    "- [**Question 2: Baseline modeling [21 pts]**](#part2)\n",
    "\n",
    "\n",
    "- [**Question 3: Predicting without using `race` [19 pts]**](#part3)\n",
    "\n",
    "\n",
    "- [**Question 4: Classification thresholds and fairness [34 pts]**](#part4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "\n",
    "## Required reading and data description\n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "### Required reading\n",
    "\n",
    "The required readings for this homework are two articles that report on the effectiveness of and issues surrounding the COMPAS recidivism algorithm used in U.S. courts. One article is published by ProPublica and the other by the MIT Technology Review:\n",
    "\n",
    "1. Angwin, Julia; Larson, Jeff; Mattu, Surya; Kirchner, Lauren (2016). \"Machine Bias: There’s software used across the country to predict future criminals. And it’s biased against blacks.\" ProPublica, May 23, 2016. https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing\n",
    "\n",
    "\n",
    "2. Hao, Karen; Stray, Jonathan (2019). \"Can you make AI fairer than a judge? Play our courtroom algorithm game: The US criminal legal system uses predictive algorithms to try to make the judicial process less biased. But there’s a deeper problem.\" MIT Technology Review, October 17, 2019. https://www.technologyreview.com/2019/10/17/75285/ai-fairer-than-judge-criminal-risk-assessment-algorithm/\n",
    "\n",
    "You will need to read these articles for the sufficient background needed to successfully complete this homework assignment. It may also be useful to refer back to content covered during the mid-semester lecture on ethics: [Lecture 11: EthiCS](https://edstem.org/us/courses/26506/lessons/46044/slides/263725).\n",
    "\n",
    "### Data description\n",
    "\n",
    "In this assignment, we will be analyzing a portion of the data set used by ProPublica in their report. The data are found in the `compas.csv` file and the \"data dictionary\", which very briefly explains each variable in the data set, can be found in the `compas_datadict.csv` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"part1\"></a>\n",
    "\n",
    "## <div class='exercise'>Question 1: Data exploration [26 pts]</div> \n",
    "    \n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code provided below will load, preprocess, and split the COMPAS data into train and test sets for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "compas_df = pd.read_csv(\"data/compas.csv\")\n",
    "\n",
    "# Inspect the original dataframe shape\n",
    "print(\n",
    "    \"Prior to processing our data, the original COMPAS dataframe was \"\n",
    "    \"shape:\\n\\n\\t{}\\n\\nAnd, these were the first several observations:\"\n",
    "    .format(compas_df.shape)\n",
    ")\n",
    "\n",
    "# Inspect original a few observations prior to processing the attributes\n",
    "display(compas_df.head())\n",
    "\n",
    "# Process binary categorical variables\n",
    "compas_df[\"sex\"] = (compas_df[\"sex\"] == \"Male\").astype(int)\n",
    "\n",
    "# print(compas_df[\"c_charge_degree\"].value_counts())\n",
    "compas_df[\"felony\"] = (compas_df[\"c_charge_degree\"] == \"F\").astype(int)\n",
    "\n",
    "# One-hot-encode the race variable\n",
    "one_hot_df = pd.get_dummies(\n",
    "    compas_df[\"race\"], prefix=\"race\", drop_first=False\n",
    ")\n",
    "compas_race_df = pd.concat(\n",
    "    [compas_df.drop(\"race\", axis=1), one_hot_df], axis=1\n",
    ")\n",
    "\n",
    "# Drop the categorical variables and leave n-1 race columns\n",
    "compas_race_df = compas_race_df.drop(\n",
    "    [\n",
    "        \"c_charge_degree\",\n",
    "        \"c_charge_desc\",\n",
    "        \"score_text\",\n",
    "        \"race_Other\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Make 80-20 train-test split, stratifying on race\n",
    "train_df, test_df = train_test_split(\n",
    "    compas_race_df,\n",
    "    train_size=0.8,\n",
    "    stratify=compas_df[\"race\"],\n",
    "    random_state=50,\n",
    ")\n",
    "\n",
    "# Inspect training dataframe after processing and splitting the data\n",
    "print(\n",
    "    \"\\n\\nAfter processing and splitting our data, our training and test\"\n",
    "    \" data were of the shapes:\\n\\n\\t{}\\t{}\\n\\nAnd, these were the first\"\n",
    "    \" several observations of the training set:\"\n",
    "    .format(train_df.shape, test_df.shape)\n",
    ")\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**1.1** What is the statistical objective of the COMPAS algorithm?  How is recidivism prediction used in courtrooms?\n",
    "\n",
    "</div>\n",
    "\n",
    "_Points:_ 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**1.2** Use the information in the provided `compas_datadict.csv` to answer the following question about the variables in the dataset:\n",
    "    \n",
    "* Which variables are raw data?  Which are pre-processed data? Justify your answer.\n",
    "* Which is the target variable of the COMPAS algorithm?\n",
    "* Which are output(s) of the COMPAS algorithm?\n",
    "* Which should not be used in building our own model to predict recidivism? Why?\n",
    "\n",
    "</div>\n",
    "\n",
    "_Points:_ 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**1.3** Now we will do a little EDA. Code has been provided to generate a visualization that explores which **unprocessed** quantitative variables, including `decile_score` (**not** the derived binary variables or pre-processed versions of the available quantitative variables, for example), are related to `race`. Feel free to create additional plots of your own if you like.\n",
    "\n",
    "Based on the visualization(s), report which 3 variables appear to have the most significant differences between Caucasians and African Americans. Briefly interpret your findings for each of those 3 variables, being certain to explain your justification for choosing each.\n",
    "\n",
    "**NOTE:** As illustrated by [the required readings](#intro), reporting on the U.S. Criminal Justice system often concentrates on the disparate experiences between Caucasians and African Americans, thus we have focused our approaches similarly. However, to ensure the efficacy of our models in Question 2 and Question 3, we must be certain to still keep observations for all racial groups included in our data. \n",
    "</div>\n",
    "\n",
    "_Points:_ 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of unprocessed variables and decile score (e.g.,\n",
    "# should not include any that are pre-processed in\n",
    "# compas.csv)\n",
    "chosen_cols = [\n",
    "    \"age\",\n",
    "    \"priors_count\",\n",
    "    \"juv_fel_count\",\n",
    "    \"juv_misd_count\",\n",
    "    \"juv_other_count\",\n",
    "    \"length_of_stay\",\n",
    "    \"decile_score\"\n",
    "]\n",
    "\n",
    "# Generate indices for subsetting data based on racial group\n",
    "aa_idx_train = np.where(train_df[\"race_African-American\"]==1)[0]\n",
    "cc_idx_train = np.where(train_df[\"race_Caucasian\"]==1)[0]\n",
    "non_aa_cc_idx_train = np.where(\n",
    "    np.all(\n",
    "        [\n",
    "            train_df[\"race_Caucasian\"]==0,\n",
    "            train_df[\"race_African-American\"]==0\n",
    "        ],\n",
    "        axis=0\n",
    "    )\n",
    ")[0]\n",
    "\n",
    "# Generate plots as required\n",
    "fig, axes = plt.subplots(4, 2, figsize=(11, 9.5))\n",
    "\n",
    "labels = [\"African-American\", \"Caucasian\", \"All Other Groups\"]\n",
    "indices = [aa_idx_train, cc_idx_train, non_aa_cc_idx_train]\n",
    "colors = [\"tab:blue\", \"tab:orange\", \"none\"]\n",
    "edgecolors = [\"none\", \"none\", \"k\"]\n",
    "alphas = [0.4, 0.4, 0.2]\n",
    "\n",
    "plt.suptitle(\n",
    "    \"Marginal distributions of unprocessed quantitative attributes\\n\"\n",
    "    \"and decile score by racial group in the training data\",\n",
    "    fontsize=15,\n",
    "    y=1,\n",
    ")\n",
    "\n",
    "for i, (col, ax) in enumerate(zip(chosen_cols, axes.flatten())):\n",
    "    for j, (idx, label, color, alpha, edgecolor) in enumerate(\n",
    "        zip(indices, labels, colors, alphas, edgecolors)\n",
    "    ):\n",
    "\n",
    "        min_val = train_df[col].min()\n",
    "        max_val = train_df[col].max()\n",
    "        \n",
    "        # Plot as barplot if variable has small range of discrete values\n",
    "        if max_val < 40:\n",
    "            n_obs = len(idx) \n",
    "            val_counts = train_df[col].iloc[idx].value_counts()\n",
    "            vals = val_counts.index\n",
    "            counts = val_counts.values\n",
    "            ax.bar(\n",
    "                vals,\n",
    "                counts / n_obs,\n",
    "                alpha=alpha,\n",
    "                label=label,\n",
    "                color=color,\n",
    "                edgecolor=edgecolor,\n",
    "            )\n",
    "            ax.set_xticks(\n",
    "                range(min_val, max_val+1) if max_val<=20\n",
    "                else range(min_val, max_val+1, 2)\n",
    "            )\n",
    "        # Plot as histogram if sufficiently large range of values\n",
    "        else:\n",
    "            ax.hist(\n",
    "                train_df[col].iloc[idx],\n",
    "                alpha=alpha,\n",
    "                label=label,\n",
    "                color=color if not \"none\" else None,\n",
    "                histtype=\"step\" if color==\"none\" else \"bar\",\n",
    "                edgecolor=edgecolor,\n",
    "                density=True,\n",
    "                bins=15,\n",
    "            )\n",
    "        if i%2==0:\n",
    "            ax.set_ylabel(\"Density\", fontsize=12)\n",
    "        if i==0:\n",
    "            ax.legend(fontsize=12)\n",
    "        ax.set_xlabel(col, fontsize=12)\n",
    "        ax.grid(\":\", alpha=0.2)\n",
    "axes[3,1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**1.4** With respect to these 3 chosen variables, how could bias in the data or data collection be impacting or causing these differences?\n",
    "\n",
    "</div>\n",
    "\n",
    "_Points:_ 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part2\"></a>\n",
    "\n",
    "## <div class=\"exercise\">Question 2: Baseline modeling [21 pts]</div> \n",
    "    \n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**2.1**  In this section we train a well-tuned, $LASSO$-like regularized logistic regression model to predict recidivism (i.e. `two_year_recid` is your response variable). We'll use the following predictors: `age`, `priors_1`, `priors_234`, `priors_5plus`, `juv_fel_1plus`, `juv_misd_1plus`, `juv_other_1plus`, `charge_any_drug`, `charge_any_violence_aggression`, `charge_any_theft`, as well as the one-hot-encoded predictors for `c_charge_degree`, `sex`, and `race`. \n",
    "    \n",
    "Inspect the resulting coefficients and interpret what this model is saying about the relationship of `two_year_recid` to `race`.\n",
    "\n",
    "</div>\n",
    "\n",
    "_Points:_ 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate predictors and response\n",
    "predictor_list = [\n",
    "    \"age\",\n",
    "    \"sex\",\n",
    "    \"priors_1\",\n",
    "    \"priors_234\",\n",
    "    \"priors_5plus\",\n",
    "    \"juv_fel_1plus\",\n",
    "    \"juv_misd_1plus\",\n",
    "    \"juv_other_1plus\",\n",
    "    \"charge_any_drug\",\n",
    "    \"charge_any_violence_aggression\",\n",
    "    \"charge_any_theft\",\n",
    "    \"felony\",\n",
    "    \"race_African-American\",\n",
    "    \"race_Asian\",\n",
    "    \"race_Caucasian\",\n",
    "    \"race_Hispanic\",\n",
    "    \"race_Native American\",\n",
    "]\n",
    "\n",
    "response_var = \"two_year_recid\"\n",
    "\n",
    "X_train = train_df[predictor_list]\n",
    "X_test = test_df[predictor_list]\n",
    "\n",
    "y_train = train_df[response_var].values\n",
    "y_test = test_df[response_var].values\n",
    "\n",
    "# Inspect shape of resulting design matrix\n",
    "print(\n",
    "    \"The shapes of our resulting X and y train and test sets \"\n",
    "    \"are:\\n\\n\\tX_train\\t{}\\n\\ty_train\\t{}\\n\\n\\tX_test\\t{}\\n\\t\"\n",
    "    \"y_test\\t{}\\n\".format(\n",
    "        X_train.shape, y_train.shape, X_test.shape, y_test.shape,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Scale data to X_train, this is required for regularization\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fit the model\n",
    "logit_model = LogisticRegressionCV(\n",
    "    penalty=\"l1\",\n",
    "    solver=\"liblinear\",\n",
    "    max_iter=1000,\n",
    "    random_state=109,\n",
    ")\n",
    "logit_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print Coefficients\n",
    "print(\n",
    "    \"The coefficients for the logistic regression model are:\"\n",
    ")\n",
    "display(\n",
    "    pd.DataFrame(\n",
    "        index=[\"intercept\"] + list(X_train.columns),\n",
    "        data={\n",
    "            \"coefficients\": np.hstack(\n",
    "                [logit_model.intercept_, logit_model.coef_[0]]\n",
    "            )\n",
    "        },\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**2.2**  The code provided below reports the following metrics on the **test set**:\n",
    "\n",
    "1. **Overall model accuracy score**\n",
    "\n",
    "\n",
    "2. **False positive rates (FPR)** for each of the two groups (please note that a \"positive\" here is `two_year_recid==1`)\n",
    "    - `African-American`\n",
    "    - `Cacausian`\n",
    "    \n",
    "3. **False negative rates (FNR)** for each of the two groups:\n",
    "    - `African-American`\n",
    "    - `Caucasian`\n",
    "\n",
    "4. **Ratios of error rates**:\n",
    "    - Ratio of the FPR between `African-American` and `Caucasian` groups\n",
    "    - Ratio of the FNR between `African-American` and `Caucasian` groups\n",
    "    - These ratios can be expressed as:\n",
    "\n",
    "$$\\frac{FPR(AA)}{FPR(CC)} \\; \\text{and} \\; \\frac{FNR(AA)}{FNR(CC)}$$\n",
    "\n",
    "\n",
    "What do you observe? Is there any disparity in the $FPR$ and $FNR$ for the two groups? What are the implications of your findings? Explain your findings in 3-6 sentences.\n",
    "\n",
    "</div>\n",
    "\n",
    "_Points:_ 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to report required metric by model in Q2.2 and Q3.2\n",
    "def evaluate_model(model, X_values, y_true, aa_idx, cc_idx):\n",
    "    \"\"\"Generate accuracy and error rate metrics for model\n",
    "    \n",
    "    Generates a set of test metrics for an input model, including\n",
    "    model accuracy, FPR and FNR for both African-American and\n",
    "    Caucasian racial groups, as well as FPR and FNR ratios\n",
    "    defined as FPR(AfAm)/FPR(Caucasion) and \n",
    "    FNR(AfAm)/FNR(Caucasion)\n",
    "    \n",
    "    :param model: estimator, fitted scikit-learn classification\n",
    "                  estimator such as LogisticRegression,\n",
    "                  DecisionTreeClassifier, etc.\n",
    "    :param X_values: np.ndarray, X matrix containing observations\n",
    "                   for prediction and evaluation\n",
    "    :param y_true: np.ndarray, true response classes\n",
    "                   corresponding to each observation in the X\n",
    "                   matrix\n",
    "    :param aa_idx: np.ndarray, array of indices corresponding to\n",
    "                   each African-American observation in the X\n",
    "                   matrix\n",
    "    :param cc_idx: np.ndarray, array of indices corresponding to\n",
    "                   each Caucasion observation in the X matrix\n",
    "    :returns: dict, resulting metrics including model accuracy,\n",
    "              FPR and FNR for both African-American and Caucasian\n",
    "              racial groups, as well as FPR and FNR ratios\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_values)\n",
    "    model_accuracy = model.score(X_values, y_true)\n",
    "\n",
    "    confusion_afam = dict(\n",
    "        zip(\n",
    "            [\"tn\",\"fp\",\"fn\",\"tp\"],\n",
    "            confusion_matrix(\n",
    "                y_true[aa_idx], y_pred[aa_idx]\n",
    "            ).ravel(),\n",
    "        )\n",
    "    )\n",
    "    confusion_caucasian = dict(\n",
    "        zip(\n",
    "            [\"tn\",\"fp\",\"fn\",\"tp\"],\n",
    "            confusion_matrix(\n",
    "                y_true[cc_idx], y_pred[cc_idx]\n",
    "            ).ravel(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fpr_afam = (\n",
    "        confusion_afam[\"fp\"] / (\n",
    "            confusion_afam[\"fp\"] + confusion_afam[\"tn\"]\n",
    "        )\n",
    "    )\n",
    "    fnr_afam = (\n",
    "        confusion_afam[\"fn\"] / (\n",
    "            confusion_afam[\"fn\"] + confusion_afam[\"tp\"]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fpr_caucasian = (\n",
    "        confusion_caucasian[\"fp\"] / (\n",
    "            confusion_caucasian[\"fp\"] + confusion_caucasian[\"tn\"]\n",
    "        )\n",
    "    )\n",
    "    fnr_caucasian = (\n",
    "        confusion_caucasian[\"fn\"] / (\n",
    "            confusion_caucasian[\"fn\"] + confusion_caucasian[\"tp\"]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fpr_ratio = fpr_afam/fpr_caucasian\n",
    "    fnr_ratio = fnr_afam/fnr_caucasian\n",
    "\n",
    "    return dict(\n",
    "        zip(\n",
    "            [\n",
    "                \"Model Accuracy\",\n",
    "                \"FPR African-American\",\n",
    "                \"FNR African-American\",\n",
    "                \"FPR Caucasian\",\n",
    "                \"FNR Caucasian\",\n",
    "                \"FPR Ratio\",\n",
    "                \"FNR Ratio\"\n",
    "            ],\n",
    "            [\n",
    "                model_accuracy,\n",
    "                fpr_afam,\n",
    "                fnr_afam,\n",
    "                fpr_caucasian,\n",
    "                fnr_caucasian,\n",
    "                fpr_ratio,\n",
    "                fnr_ratio\n",
    "            ],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the indices for each of the two races on the test set\n",
    "aa_idx_test = np.where(test_df[\"race_African-American\"]==1)[0]\n",
    "cc_idx_test = np.where(test_df[\"race_Caucasian\"]==1)[0]\n",
    "\n",
    "results_logit_model = evaluate_model(\n",
    "    logit_model,\n",
    "    X_test_scaled,\n",
    "    y_test,\n",
    "    aa_idx_test,\n",
    "    cc_idx_test,\n",
    ")\n",
    "print(\n",
    "    \"The accuracy and error rates for the model on the \"\n",
    "    \"test set are:\\n\\n\\t\\t\\tmodel with race\\n\"\n",
    ")\n",
    "    \n",
    "for key, value in results_logit_model.items():\n",
    "    print(f\"{key:20}\\t{value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part3\"></a>\n",
    "\n",
    "## <div class='exercise'>Question 3: Predicting without using `race` [19 pts]</div> \n",
    "    \n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**3.1** Now we'll fit another well-tuned, $LASSO$-like regularized logistic regression model and report the sames metrics we did in Question 2, but this time we will fit the model **without** using the `race` predictors.\n",
    "\n",
    "How do these metrics compare to those from the model that did include the `race` predictors?\n",
    "\n",
    "</div>\n",
    "\n",
    "_Points:_ 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the race columns, which are the last 5 columns in the df\n",
    "X_train_scaled_no_race = X_train_scaled[:, :-5]\n",
    "X_test_scaled_no_race = X_test_scaled[:, :-5]\n",
    "\n",
    "# Fit the model\n",
    "logit_model_no_race = LogisticRegressionCV(\n",
    "    penalty=\"l1\",\n",
    "    solver = \"liblinear\",\n",
    "    max_iter=1000,\n",
    "    random_state=109\n",
    ")\n",
    "logit_model_no_race.fit(X_train_scaled_no_race, y_train)\n",
    "\n",
    "# Print Coefficients\n",
    "print(\n",
    "    \"The coefficients for the logistic regression model \"\n",
    "    \"excluding race are:\"\n",
    ")\n",
    "\n",
    "display(\n",
    "    pd.DataFrame(\n",
    "        index=[\"intercept\"] + list(X_train.columns[:-5]),\n",
    "        data={\n",
    "            \"coefficients\": np.hstack(\n",
    "                [\n",
    "                    logit_model_no_race.intercept_,\n",
    "                    logit_model_no_race.coef_[0],\n",
    "                ]\n",
    "            )\n",
    "        },\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate and report results\n",
    "results_logit_no_race = evaluate_model(\n",
    "    logit_model_no_race,\n",
    "    X_test_scaled_no_race,\n",
    "    y_test,\n",
    "    aa_idx_test,\n",
    "    cc_idx_test,\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"The accuracy and error rates for the model on the \"\n",
    "    \"test set are:\\n\\n\\t\\t\\tmodel with race\\t\\twithout race\\n\"\n",
    ")\n",
    "    \n",
    "for (key, value), value2 in zip(\n",
    "    results_logit_model.items(), results_logit_no_race.values()\n",
    "):\n",
    "    print(f\"{key:20}\\t{value:.4f}\\t\\t\\t{value2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**3.2**  Given your exploration and modeling of the data, should a predictive tool be trusted to be unbiased even if it doesn’t explicitly use a variable such as race to predict future crime?  Why or why not? Give careful consideration to why the bias is still occurring or not still occurring in your results and what the real-life implications/effects might be for such a tool.\n",
    "\n",
    "</div>\n",
    "\n",
    "_Points:_ 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part4\"></a>\n",
    "\n",
    "## <div class='exercise'>Question 4: Classification thresholds and fairness [34 pts]</div> \n",
    "\n",
    "Below is code that plots the Receiver Operating Characteristic (ROC) curves from the question 3 model for two racial groups: `African-American` and `Caucasian` on the **training set**. In question 4, we will explore the false positice and false negative rates of this model further.\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predicted probabilities for training observations\n",
    "preds_proba = logit_model_no_race.predict_proba(\n",
    "    X_train_scaled_no_race\n",
    ")[:,1]\n",
    "\n",
    "\n",
    "# Generate AUC score separately for African-American and \n",
    "# Caucasian observations \n",
    "auc_score_aa = roc_auc_score(\n",
    "    y_train[aa_idx_train], preds_proba[aa_idx_train]\n",
    ")\n",
    "auc_score_cc = roc_auc_score(\n",
    "    y_train[cc_idx_train], preds_proba[cc_idx_train]\n",
    ")\n",
    "\n",
    "# Generate ROC curve values separately for African-American \n",
    "# and Caucasian observations\n",
    "fpr_aa, tpr_aa, thresholds_aa = roc_curve(\n",
    "    y_train[aa_idx_train], preds_proba[aa_idx_train]\n",
    ")\n",
    "fpr_cc, tpr_cc, thresholds_cc = roc_curve(\n",
    "    y_train[cc_idx_train], preds_proba[cc_idx_train]\n",
    ")\n",
    "\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(9, 5.25))\n",
    "plt.plot(\n",
    "    fpr_aa,\n",
    "    tpr_aa,\n",
    "    label=f\"African-American\\n$AUC={auc_score_aa:.3f}$\",\n",
    ")\n",
    "plt.plot(\n",
    "    fpr_cc,\n",
    "    tpr_cc,\n",
    "    label=f\"Caucasian\\n$AUC={auc_score_cc:.3f}$\",\n",
    ")\n",
    "plt.plot([0, 1], [0, 1], color=\"k\", linestyle=\":\", alpha=0.5)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate ($FPR$)\", fontsize=12)\n",
    "plt.ylabel(\"True Positive Rate ($TPR$)\", fontsize=12)\n",
    "plt.title(\n",
    "    \"Receiver operating characteristic curves by racial group\\n\"\n",
    "    \"based on training observations\",\n",
    "    fontsize=16\n",
    ")\n",
    "plt.legend(fontsize=12, edgecolor=\"k\")\n",
    "plt.grid(\":\", alpha=0.4)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**4.1** The default threshold used for determining the classification metrics analyzed in Question 2 and Question 3 was $\\hat{p}=0.5$.  Choose a new single threshold for the model from question 3 that will reduce the bias between these two racial groups as measured by the \"Ratios of Error Rates\" (as defined by the formulas shown in Question 2). Be certain to justify your choice and interpet how this threshold choice affects your model results.\n",
    "\n",
    "**HINT:** There is no one correct answer here. However, to arrive at an answer you can support with an evidence-based justification, you will likely need to inspect the \"Ratio of $FPR$\", \"Ratio of $FNR$\", and accuracy trends across varying classification thresholds. There should be no need to refit your model from question 3 to accomplish this task. You can use the code provide to help make your decision, but again, feel free to create your own additional plots if you like.\n",
    "\n",
    "</div>\n",
    "\n",
    "_Points:_ 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to report required metrics by model and threshold\n",
    "def evaluate_model_threshold(\n",
    "    model, X_values, y_true, aa_idx, cc_idx, threshold\n",
    "):\n",
    "    \"\"\"Generate metrics for model at a given threshold\n",
    "    \n",
    "    Generates a set of test metrics for an input model, including\n",
    "    model accuracy and FPR and FNR for all observations and both\n",
    "    African-American and Caucasian racial groups individually, as\n",
    "    well as FPR and FNR ratios defined as FPR(AfAm)/FPR(Caucasion)\n",
    "    and FNR(AfAm)/FNR(Caucasion)\n",
    "    \n",
    "    :param model: estimator, fitted scikit-learn classification\n",
    "                  estimator such as LogisticRegression,\n",
    "                  DecisionTreeClassifier, etc.\n",
    "    :param X_values: np.ndarray, X matrix containing observations\n",
    "                   for prediction and evaluation\n",
    "    :param y_true: np.ndarray, true response classes\n",
    "                   corresponding to each observation in the X\n",
    "                   matrix\n",
    "    :param aa_idx: np.ndarray, array of indices corresponding to\n",
    "                   each African-American observation in the X\n",
    "                   matrix\n",
    "    :param cc_idx: np.ndarray, array of indices corresponding to\n",
    "                   each Caucasion observation in the X matrix\n",
    "    :param threshold: float, classification threshold, 0 to 1,\n",
    "                      at which to evaluate model\n",
    "    :returns: dict, resulting metrics including model accuracy,\n",
    "              FPR, and FNR for all observations and both\n",
    "              African-American and Caucasian racial groups, as\n",
    "              well as FPR and FNR ratios\n",
    "    \"\"\"\n",
    "    y_pred_proba = model.predict_proba(X_values)[:,1]\n",
    "    y_preds = np.where(y_pred_proba >= threshold, 1, 0)\n",
    "    model_accuracy = accuracy_score(y_preds, y_true)\n",
    "    model_accuracy_afam = accuracy_score(\n",
    "        y_preds[aa_idx], y_true[aa_idx]\n",
    "    )\n",
    "    model_accuracy_caucasian = accuracy_score(\n",
    "        y_preds[cc_idx], y_true[cc_idx]\n",
    "    )\n",
    "    \n",
    "    confusion_overall = dict(\n",
    "        zip(\n",
    "            [\"tn\",\"fp\",\"fn\",\"tp\"],\n",
    "            confusion_matrix(\n",
    "                y_true, y_preds\n",
    "            ).ravel(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    confusion_afam = dict(\n",
    "        zip(\n",
    "            [\"tn\",\"fp\",\"fn\",\"tp\"],\n",
    "            confusion_matrix(\n",
    "                y_true[aa_idx], y_preds[aa_idx]\n",
    "            ).ravel(),\n",
    "        )\n",
    "    )\n",
    "    confusion_caucasian = dict(\n",
    "        zip(\n",
    "            [\"tn\",\"fp\",\"fn\",\"tp\"],\n",
    "            confusion_matrix(\n",
    "                y_true[cc_idx], y_preds[cc_idx]\n",
    "            ).ravel(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fpr_all = (\n",
    "        confusion_overall[\"fp\"] / (\n",
    "            confusion_overall[\"fp\"] + confusion_overall[\"tn\"]\n",
    "        )\n",
    "    )\n",
    "    fnr_all = (\n",
    "        confusion_overall[\"fn\"] / (\n",
    "            confusion_overall[\"fn\"] + confusion_overall[\"tp\"]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    \n",
    "    fpr_afam = (\n",
    "        confusion_afam[\"fp\"] / (\n",
    "            confusion_afam[\"fp\"] + confusion_afam[\"tn\"]\n",
    "        )\n",
    "    )\n",
    "    fnr_afam = (\n",
    "        confusion_afam[\"fn\"] / (\n",
    "            confusion_afam[\"fn\"] + confusion_afam[\"tp\"]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fpr_caucasian = (\n",
    "        confusion_caucasian[\"fp\"] / (\n",
    "            confusion_caucasian[\"fp\"] + confusion_caucasian[\"tn\"]\n",
    "        )\n",
    "    )\n",
    "    fnr_caucasian = (\n",
    "        confusion_caucasian[\"fn\"] / (\n",
    "            confusion_caucasian[\"fn\"] + confusion_caucasian[\"tp\"]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    with np.errstate(all=\"raise\"):\n",
    "        try:\n",
    "            fpr_ratio = fpr_afam/fpr_caucasian\n",
    "        except:\n",
    "            fpr_ratio = 0\n",
    "\n",
    "        try:\n",
    "            fnr_ratio = fnr_afam/fnr_caucasian\n",
    "        except:\n",
    "            fnr_ratio = 0\n",
    "\n",
    "    return dict(\n",
    "        zip(\n",
    "            [\n",
    "                \"threshold\",\n",
    "                \"model_accuracy\",\n",
    "                \"model_accuracy_afam\",\n",
    "                \"model_accuracy_caucasian\",\n",
    "                \"fpr_all\",\n",
    "                \"fnr_all\",\n",
    "                \"fpr_afam\",\n",
    "                \"fnr_afam\",\n",
    "                \"fpr_caucasian\",\n",
    "                \"fnr_caucasian\",\n",
    "                \"fpr_ratio\",\n",
    "                \"fnr_ratio\"\n",
    "            ],\n",
    "            [\n",
    "                threshold,\n",
    "                model_accuracy,\n",
    "                model_accuracy_afam,\n",
    "                model_accuracy_caucasian,\n",
    "                fpr_all,\n",
    "                fnr_all,\n",
    "                fpr_afam,\n",
    "                fnr_afam,\n",
    "                fpr_caucasian,\n",
    "                fnr_caucasian,\n",
    "                fpr_ratio,\n",
    "                fnr_ratio\n",
    "            ],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of 100 thresholds, p=[0, 1]\n",
    "t_vals = np.arange(0, 1.01, 0.01)\n",
    "\n",
    "# instantiate dict for storing results at each threshold\n",
    "results_dict_train, results_dict_test = {}, {}\n",
    "\n",
    "# generate train and test results at each threshold and store to dicts\n",
    "for i, t in enumerate(t_vals):\n",
    "    result_train = evaluate_model_threshold(\n",
    "        logit_model_no_race,\n",
    "        X_train_scaled_no_race,\n",
    "        y_train, \n",
    "        aa_idx_train,\n",
    "        cc_idx_train,\n",
    "        threshold=t,\n",
    "    )    \n",
    "    result_test = evaluate_model_threshold(\n",
    "        logit_model_no_race,\n",
    "        X_test_scaled_no_race,\n",
    "        y_test, \n",
    "        aa_idx_test,\n",
    "        cc_idx_test,\n",
    "        threshold=t,\n",
    "    )    \n",
    "\n",
    "    for key, val in result_train.items():\n",
    "        # use dict.setdefault method to append val list for each\n",
    "        # key. For more info on this use of the method...\n",
    "        # see here: https://docs.python.org/3/library/\n",
    "        #           stdtypes.html#dict.setdefault\n",
    "        # and here: https://stackoverflow.com/a/26367880\n",
    "        results_dict_train.setdefault(key, []).append(val)\n",
    "\n",
    "    for key, val in result_test.items():\n",
    "        results_dict_test.setdefault(key, []).append(val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_threshold(threshold):\n",
    "    # instantiate lists for plotting axes\n",
    "    key_list = [\"fpr_ratio\", \"fnr_ratio\", \"model_accuracy\"]\n",
    "    title_list = [\"$FPR$ ratio\", \"$FNR$ ratio\", \"Model accuracy\"]\n",
    "\n",
    "    # generate plot\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(10, 7), sharex=True)\n",
    "\n",
    "    for i, (ax, key, title) in enumerate(\n",
    "        zip(axes, key_list, title_list)\n",
    "    ):\n",
    "        ax.plot(results_dict_train[\"threshold\"], results_dict_train[key])\n",
    "        ax.set_ylabel(\n",
    "            \"Ratio\" if \"ratio\" in title else \"Accuracy\",\n",
    "            fontsize=12\n",
    "        )\n",
    "        ax.axvline(\n",
    "            threshold,\n",
    "            color=\"k\",\n",
    "            linestyle=\"--\",\n",
    "            label=\"Proposed threshold: $\\hat{{p}}={:.2f}$\".format(\n",
    "                threshold\n",
    "            ),\n",
    "        )\n",
    "        ax.axhline(\n",
    "            results_dict_train[key][50],\n",
    "            color=\"tab:red\",\n",
    "            linestyle=\":\",\n",
    "            label=\"Metrics values at default threshold $\\hat{{p}}=0.5$\"\n",
    "        )\n",
    "        ax.set_title(title)\n",
    "        ax.grid(\":\", alpha=0.4)\n",
    "        if i==0:\n",
    "            ax.legend(edgecolor=\"k\", fontsize=11)\n",
    "        if i==2:\n",
    "            ax.set_xlabel(\"Classification threshold\", fontsize=12)\n",
    "\n",
    "    plt.suptitle(\n",
    "        \"Ratios of error rates \"\n",
    "        \"$\\left( \\; \\\\frac{FPR(AA)}{FPR(CC)} \\; and \\; \"\n",
    "        \"\\\\frac{FNR(AA)}{FNR(CC)} \\; \\\\right)$ \"\n",
    "        \"and model accuracy\\nby classification threshold \"\n",
    "        \"on the TRAINING data\",\n",
    "        fontsize=15,\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # print summary results\n",
    "    group_list = [\"Caucasian\", \"African-American\"]\n",
    "    var_list = [\"caucasian\", \"afam\"]\n",
    "    threshold_indices = [int(threshold*1E+2)]*2\n",
    "\n",
    "    print(\n",
    "        \"Naive model accuracy results, predicting all observations \"\n",
    "        \"as Class 0\\nbased on {:.4f} overall proportion Class 1 in \"\n",
    "        \"training observations:\\n\\n\\t\\t\\t\\tTrain\\t\\tTEST\\n\"\n",
    "        \"\\tCaucasian\\t\\t{:.4f}\\t\\t{:.4f}\\n\"\n",
    "        \"\\tAfrican-American\\t{:.4f}\\t\\t{:.4f}\\n\"\n",
    "        \"\\tAll Observations\\t{:.4f}\\t\\t{:.4f}\\n\".format(\n",
    "            sum(y_train)/len(y_train),\n",
    "            1-sum(y_train[cc_idx_train])/len(y_train[cc_idx_train]),\n",
    "            1-sum(y_test[cc_idx_test])/len(y_test[cc_idx_test]),\n",
    "            1-sum(y_train[aa_idx_train])/len(y_train[aa_idx_train]),\n",
    "            1-sum(y_test[aa_idx_test])/len(y_test[aa_idx_test]),\n",
    "            1-sum(y_train)/len(y_train),\n",
    "            1-sum(y_test)/len(y_test),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for group, var, t_idx in zip(\n",
    "        group_list, var_list, threshold_indices\n",
    "    ):\n",
    "        print(\n",
    "            \"{} results with proposed threshold p={:.2f}:\\n\\n\"\n",
    "            \"\\t\\t\\tTrain\\t\\tTEST\\n\"\n",
    "            \"\\tFPR\\t\\t{:.4f}\\t\\t{:.4f}\\n\"\n",
    "            \"\\tFNR\\t\\t{:.4f}\\t\\t{:.4f}\"\n",
    "            \"\\n\\tAccuracy\\t{:.4f}\\t\\t{:.4f}\\n\"\n",
    "            .format(\n",
    "                group,\n",
    "                results_dict_train['threshold'][t_idx],\n",
    "                results_dict_train[f\"fpr_{var}\"][t_idx],\n",
    "                results_dict_test[f\"fpr_{var}\"][t_idx],\n",
    "                results_dict_train[f\"fnr_{var}\"][t_idx],\n",
    "                results_dict_test[f\"fnr_{var}\"][t_idx],\n",
    "                results_dict_train[f\"model_accuracy_{var}\"][t_idx],\n",
    "                results_dict_test[f\"model_accuracy_{var}\"][t_idx],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        \"Overall results (all racial groups) with proposed \"\n",
    "        \"threshold p={:.2f}:\\n\\n\\t\\t\\tTrain\\t\\tTEST\\n\"\n",
    "        \"\\tFPR\\t\\t{:.4f}\\t\\t{:.4f}\\n\\tFNR\\t\\t{:.4f}\\t\\t{:.4f}\"\n",
    "        \"\\n\\tAccuracy\\t{:.4f}\\t\\t{:.4f}\\n\".format(\n",
    "            results_dict_train['threshold'][t_idx],\n",
    "            results_dict_train[f\"fpr_all\"][t_idx],\n",
    "            results_dict_test[f\"fpr_all\"][t_idx],\n",
    "            results_dict_train[f\"fnr_all\"][t_idx],\n",
    "            results_dict_test[f\"fnr_all\"][t_idx],\n",
    "            results_dict_train[f\"model_accuracy\"][t_idx],\n",
    "            results_dict_test[f\"model_accuracy\"][t_idx],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set threshold for plotting and evaluating\n",
    "threshold = ...\n",
    "plot_threshold(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**4.2** A second approach to reducing bias is to use different thresholds for the different racial groups to better ensure that the individual groups have similar false positive and false negative rates.  Choose a pair of thresholds (one for the `African-American` group and one for the `Caucasian` group) that improves the group bias (while still taking accuracy into consideration). Be certain to justify your choices and interpet how these threshold choices affect your model results.\n",
    "\n",
    "**HINT:** To arrive at an answer you can support with an evidence-based justification, you will likely need to inspect $FPR$, $FNR$, and accuracy trends across varying classification thresholds for each group (`African-American` and `Caucasian`) individually. There should be no need to refit your model from Question 3 to accomplish this task. Again, the plotting code provided can be used to help decide on a pair of thresholds.\n",
    "\n",
    "</div>\n",
    "\n",
    "_Points:_ 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_threshold_pair(t_cc, t_afam):\n",
    "    # instantiate lists for plotting axes\n",
    "    group_list = [\"Caucasian\", \"African-American\"]\n",
    "    var_list = [\"caucasian\", \"afam\"]\n",
    "    threshold_list = [t_cc, t_afam]\n",
    "\n",
    "\n",
    "    # Generate plots\n",
    "    fig, axes = plt.subplots(1, 2, sharey=True, figsize=(10, 4.5))\n",
    "    plt.suptitle(\n",
    "        '$FNR$, $FPR$, and accuracy trend and proposed \"balanced\"\\n'\n",
    "        \"classification thresholds by racial group using \"\n",
    "        \"the TRAINING data\",\n",
    "        fontsize=16,\n",
    "        y=1,\n",
    "    )\n",
    "\n",
    "    for i, (group, var, threshold, ax) in enumerate(\n",
    "        zip(group_list, var_list, threshold_list, axes)\n",
    "    ):\n",
    "\n",
    "        ax.plot(\n",
    "            results_dict_train[\"threshold\"],\n",
    "            results_dict_train[f\"fnr_{var}\"],\n",
    "            label=\"FNR\",\n",
    "        )\n",
    "        ax.plot(\n",
    "            results_dict_train[\"threshold\"],\n",
    "            results_dict_train[f\"fpr_{var}\"],\n",
    "            label=\"FPR\",\n",
    "        )\n",
    "        ax.plot(\n",
    "            results_dict_train[\"threshold\"],\n",
    "            results_dict_train[f\"model_accuracy_{var}\"],\n",
    "            \"k-\",\n",
    "            label=\"Accuracy\",\n",
    "        )\n",
    "        ax.axvline(\n",
    "            threshold,\n",
    "            color=\"k\",\n",
    "            linestyle=\"--\",\n",
    "            label=\"Proposed\\nthreshold\",\n",
    "        )\n",
    "        ax.set_title(f\"{group} training observations\", fontsize=14)\n",
    "        ax.set_xlabel(\"Classification threshold\", fontsize=12)\n",
    "        ax.grid(\":\", alpha=0.4)\n",
    "\n",
    "        if i==0:\n",
    "            ax.legend(edgecolor=\"k\", fontsize=12, loc=(.66, .11))\n",
    "            ax.set_ylabel(\"Resulting metric value\", fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # print summary results\n",
    "    threshold_indices = [int(t_cc*1E+2), int(t_afam*1E+2)]\n",
    "\n",
    "    for group, var, t_idx in zip(\n",
    "        group_list, var_list, threshold_indices\n",
    "    ):\n",
    "        print(\n",
    "            \"{} results with proposed threshold p={:.2f}:\\n\\n\"\n",
    "            \"\\t\\t\\tTrain\\t\\tTEST\\n\"\n",
    "            \"\\tFPR\\t\\t{:.4f}\\t\\t{:.4f}\\n\"\n",
    "            \"\\tFNR\\t\\t{:.4f}\\t\\t{:.4f}\"\n",
    "            \"\\n\\tAccuracy\\t{:.4f}\\t\\t{:.4f}\\n\"\n",
    "            .format(\n",
    "                group,\n",
    "                results_dict_train['threshold'][t_idx],\n",
    "                results_dict_train[f\"fpr_{var}\"][t_idx],\n",
    "                results_dict_test[f\"fpr_{var}\"][t_idx],\n",
    "                results_dict_train[f\"fnr_{var}\"][t_idx],\n",
    "                results_dict_test[f\"fnr_{var}\"][t_idx],\n",
    "                results_dict_train[f\"model_accuracy_{var}\"][t_idx],\n",
    "                results_dict_test[f\"model_accuracy_{var}\"][t_idx],\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# identify balanced thresholds\n",
    "# thresholds for Caucasians \n",
    "t_cc = ...\n",
    "\n",
    "# threshold for African Americans\n",
    "t_afam = ...\n",
    "\n",
    "plot_threshold_pair(t_cc, t_afam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**4.3** Comment on [the fairness](<https://en.wikipedia.org/wiki/Fairness_(machine_learning)>) of the two methods in Question 4.1 and Question 4.2 from two different perspectives: the fairness of each group (called \"group fairness\") and the fairness for an individual defendant (called \"individual fairness\"). \n",
    "\n",
    "</div>\n",
    "\n",
    "_Points:_ 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'>\n",
    "\n",
    "**4.4** Changing the thresholds can *reduce* bias between the two classes, but it can also affect model accuracy. We want our model to be **accurate** but also **fair**.  What can be done to balance these two criteria?  Write down your strategy to overcome this difficulty. Please limit your response to at most 150 words.  \n",
    "\n",
    "</div>\n",
    "\n",
    "_Points:_ 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**This concludes HW7. Thank you!**\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
